åœ¨[äººå·¥ç¥ç»ç½‘ç»œ](https://en.wikipedia.org/wiki/Artificial_neural_networks)ä¸­ï¼Œ **å¾ªç¯ç¥ç»ç½‘ç»œ** ( **RNN** ) æ—¨åœ¨å¤„ç†åºåˆ—æ•°æ®ï¼Œä¾‹å¦‚æ–‡æœ¬ã€è¯­éŸ³å’Œ[æ—¶é—´åºåˆ— ](https://en.wikipedia.org/wiki/Time_series)[[ 1 \]](https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-1) ï¼Œå…¶ä¸­å…ƒç´ çš„é¡ºåºéå¸¸é‡è¦ã€‚ä¸ç‹¬ç«‹å¤„ç†è¾“å…¥çš„[å‰é¦ˆç¥ç»ç½‘ç»œ](https://en.wikipedia.org/wiki/Feedforward_neural_network)ä¸åŒï¼ŒRNN åˆ©ç”¨å¾ªç¯è¿æ¥ï¼Œå…¶ä¸­ä¸€ä¸ªç¥ç»å…ƒåœ¨ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºä¼šåé¦ˆåˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ä½œä¸ºç½‘ç»œçš„è¾“å…¥ã€‚è¿™ä½¿å¾— RNN èƒ½å¤Ÿæ•æ‰åºåˆ—ä¸­çš„æ—¶é—´ä¾èµ–å…³ç³»å’Œæ¨¡å¼ã€‚

ä¼ ç»Ÿçš„å¾ªç¯ç¥ç»ç½‘ç»œ (RNN) å­˜åœ¨[æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ ](https://en.wikipedia.org/wiki/Vanishing_gradient_problem)ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å­¦ä¹ é•¿ç¨‹ä¾èµ–å…³ç³»çš„èƒ½åŠ›ã€‚1997 å¹´ï¼Œ[ é•¿çŸ­æœŸè®°å¿† ](https://en.wikipedia.org/wiki/Long_short-term_memory)(LSTM) æ¶æ„çš„å‡ºç°è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œä½¿å…¶æˆä¸ºå¤„ç†é•¿ç¨‹ä¾èµ–å…³ç³»çš„æ ‡å‡† RNN å˜ä½“ã€‚åæ¥ï¼Œ[ é—¨æ§å¾ªç¯å•å…ƒ ](https://en.wikipedia.org/wiki/Gated_recurrent_unit)(GRU) ä½œä¸ºä¸€ç§è®¡ç®—æ•ˆç‡æ›´é«˜çš„æ›¿ä»£æ–¹æ¡ˆè¢«å¼•å…¥ã€‚



# RNN

å¥½çš„ ğŸ‘ æˆ‘ç»™ä½ æ•´ç†ä¸€ä¸ª**RNN çš„é¢è¯•é€ŸèƒŒç‰ˆæ€»ç»“**ï¼Œç®€æ˜åˆå…¨é¢ï¼Œé€‚åˆç›´æ¥åœ¨é¢è¯•é‡Œå¤è¿°ã€‚

![File:Recurrent neural network unfold.svg](assets/960px-Recurrent_neural_network_unfold.svg.png)

------

# ğŸš€ RNN ç®€å•æ€»ç»“

1. **å…¨ç§°**ï¼šRecurrent Neural Networkï¼Œå¾ªç¯ç¥ç»ç½‘ç»œã€‚

   - ç”¨æ¥å¤„ç† **åºåˆ—æ•°æ®**ï¼ˆæ–‡æœ¬ã€è¯­éŸ³ã€æ—¶é—´åºåˆ—ï¼‰ã€‚
   - ç‰¹ç‚¹ï¼šå‰ä¸€æ—¶åˆ»çš„éšè—çŠ¶æ€ä¼šä¼ é€’ç»™åä¸€æ—¶åˆ»ï¼Œå®ç°å¯¹ä¸Šä¸‹æ–‡çš„è®°å¿†ã€‚

2. **æ ¸å¿ƒç»“æ„**ï¼š

   - æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ xtx_tï¼Œç»“åˆå‰ä¸€æ—¶åˆ»çš„éšè—çŠ¶æ€ htâˆ’1h_{t-1}ï¼Œè®¡ç®—å½“å‰çŠ¶æ€ï¼š

     ht=f(Whhtâˆ’1+Wxxt+b)h_t = f(W_h h_{t-1} + W_x x_t + b)

   - è¾“å‡ºå¯ä»¥æ˜¯åºåˆ—ï¼ˆmany-to-manyï¼Œå¦‚ç¿»è¯‘ï¼‰æˆ–å•å€¼ï¼ˆmany-to-oneï¼Œå¦‚åˆ†ç±»ï¼‰ã€‚

3. **ä¼˜ç‚¹**ï¼š

   - èƒ½å¤Ÿå»ºæ¨¡åºåˆ—çš„æ—¶åºä¾èµ–å…³ç³»ã€‚
   - ç»“æ„ç®€å•ï¼Œæ€æƒ³ç›´è§‚ã€‚

4. **ç¼ºç‚¹**ï¼š

   - **æ¢¯åº¦æ¶ˆå¤±/æ¢¯åº¦çˆ†ç‚¸**ï¼šåœ¨é•¿åºåˆ—ä¸­éš¾ä»¥æ•æ‰é•¿æœŸä¾èµ–ã€‚
   - **éš¾ä»¥å¹¶è¡Œ**ï¼šå¿…é¡»é€æ­¥è®¡ç®—ï¼Œè®­ç»ƒæ•ˆç‡ä½ã€‚
   - å®¹é‡æœ‰é™ï¼Œè¡¨è¾¾èƒ½åŠ›å—é™ã€‚

5. **æ”¹è¿›æ¨¡å‹**ï¼š

   - **LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ï¼‰**ï¼šå¼•å…¥è®°å¿†å•å…ƒå’Œé—¨æœºåˆ¶ã€‚
   - **GRUï¼ˆé—¨æ§å¾ªç¯å•å…ƒï¼‰**ï¼šç®€åŒ–ç‰ˆ LSTMï¼Œæ•ˆç‡æ›´é«˜ã€‚

------

# é¢è¯•é€Ÿç­”æ¨¡æ¿

*â€œRNN æ˜¯å¾ªç¯ç¥ç»ç½‘ç»œï¼Œç”¨æ¥å¤„ç†åºåˆ—æ•°æ®ã€‚å®ƒçš„ç‰¹ç‚¹æ˜¯æŠŠå‰ä¸€æ—¶åˆ»çš„éšè—çŠ¶æ€ä¼ é€’ç»™ä¸‹ä¸€æ—¶åˆ»ï¼Œä»è€Œå»ºæ¨¡ä¸Šä¸‹æ–‡ä¾èµ–ã€‚ä¼˜ç‚¹æ˜¯é€‚åˆå¤„ç†æ—¶åºä»»åŠ¡ï¼Œä½†ç¼ºç‚¹æ˜¯å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±ã€éš¾ä»¥å¹¶è¡Œï¼Œå¯¼è‡´å¯¹é•¿è·ç¦»ä¾èµ–å»ºæ¨¡èƒ½åŠ›å·®ã€‚åæ¥å‡ºç°äº† LSTM å’Œ GRU æ¥æ”¹è¿›è¿™äº›é—®é¢˜ï¼Œç°åœ¨æ›´å¤šä½¿ç”¨ Transformer æ¥æ›¿ä»£ã€‚â€*



---

# LSTM

å¥½çš„ ğŸ‘ æˆ‘ç»™ä½ æ•´ç†ä¸€ä¸ª**LSTM çš„é¢è¯•é€ŸèƒŒç‰ˆ**ï¼Œç®€æ´æ˜äº†ï¼Œæ–¹ä¾¿ä½ åœ¨é¢è¯•æ—¶å¿«é€Ÿå¤è¿°ã€‚

![image-20250917150323039](assets/image-20250917150323039.png)



> ![image-20250917150451350](assets/image-20250917150451350.png)
>
> ## ğŸ”¹ ä¿¡æ¯æµå°ç»“
>
> - **Ïƒï¼ˆsigmoidï¼‰** â†’ è´Ÿè´£â€œé—¨æ§â€ï¼Œå†³å®šæ¯”ä¾‹ã€‚
> - **tanh** â†’ è´Ÿè´£â€œå€™é€‰å€¼/è§„èŒƒåŒ–â€ï¼Œä¿è¯æ•°å€¼èŒƒå›´ç¨³å®šã€‚
> - **âŠ—** â†’ ç”¨é—¨æ§å€¼å»ç­›é€‰ä¿¡æ¯ï¼ˆä¿ç•™/ä¸¢å¼ƒï¼‰ã€‚
> - **âŠ•** â†’ æŠŠä¸åŒæ¥æºçš„ä¿¡æ¯åˆå¹¶ï¼ˆæ—§è®°å¿† + æ–°ä¿¡æ¯ï¼‰ã€‚
>
> ------
>
> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š
>
> - **Ïƒ** = é—¨æ§ï¼ˆä¿ç•™å¤šå°‘ï¼‰
> - **tanh** = ç”Ÿæˆå€™é€‰å€¼ï¼ˆå†…å®¹æ˜¯ä»€ä¹ˆï¼‰
> - **âŠ—** = ä¹˜æ³•é—¨ï¼ˆæ¯”ä¾‹æ§åˆ¶ä¿¡æ¯ï¼‰
> - **âŠ•** = åŠ æ³•åˆå¹¶ï¼ˆæ—§è®°å¿† + æ–°ä¿¡æ¯ï¼‰



------

# ğŸš€ LSTM ç®€å•ä»‹ç»

1. **å…¨ç§°**ï¼šLong Short-Term Memoryï¼Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œã€‚
   - æ˜¯ **RNNï¼ˆå¾ªç¯ç¥ç»ç½‘ç»œï¼‰** çš„æ”¹è¿›ç‰ˆæœ¬ã€‚
   - è§£å†³äº† RNN åœ¨é•¿åºåˆ—ä¸­ **æ¢¯åº¦æ¶ˆå¤±/æ¢¯åº¦çˆ†ç‚¸** çš„é—®é¢˜ã€‚
2. **æ ¸å¿ƒæ€æƒ³**ï¼š
   - åœ¨éšè—å±‚ä¸­å¼•å…¥ä¸€ä¸ª **è®°å¿†å•å…ƒï¼ˆcell stateï¼‰**ï¼Œç”¨æ¥é•¿æœŸå­˜å‚¨ä¿¡æ¯ã€‚
   - é€šè¿‡ **é—¨æœºåˆ¶ï¼ˆgatesï¼‰** æ§åˆ¶ä¿¡æ¯çš„æµåŠ¨ã€‚
3. **ä¸‰å¤§é—¨æœºåˆ¶**ï¼š
   - **é—å¿˜é—¨ï¼ˆforget gateï¼‰**ï¼šå†³å®šä¸¢æ‰å¤šå°‘æ—§ä¿¡æ¯ã€‚
   - **è¾“å…¥é—¨ï¼ˆinput gateï¼‰**ï¼šå†³å®šå½“å‰è¾“å…¥ä¿¡æ¯æœ‰å¤šå°‘å†™å…¥è®°å¿†å•å…ƒã€‚
   - **è¾“å‡ºé—¨ï¼ˆoutput gateï¼‰**ï¼šå†³å®šä»è®°å¿†å•å…ƒè¾“å‡ºå¤šå°‘ä¿¡æ¯ã€‚
4. **ä¼˜ç‚¹**ï¼š
   - èƒ½æ•æ‰ **é•¿è·ç¦»ä¾èµ–**ã€‚
   - ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
   - åœ¨åºåˆ—å»ºæ¨¡ä»»åŠ¡ï¼ˆè¯­éŸ³ã€ç¿»è¯‘ã€æ—¶é—´åºåˆ—é¢„æµ‹ï¼‰ä¸­è¡¨ç°ä¼˜ç§€ã€‚
5. **ç¼ºç‚¹**ï¼š
   - ç»“æ„å¤æ‚ï¼Œè®­ç»ƒå¼€é”€å¤§ã€‚
   - éš¾ä»¥å¹¶è¡ŒåŒ–ï¼ˆç›¸è¾ƒäº Transformerï¼‰ã€‚

------

# é¢è¯•é€Ÿç­”æ¨¡æ¿

*â€œLSTM æ˜¯ RNN çš„æ”¹è¿›å‹ï¼Œæ ¸å¿ƒæ˜¯é€šè¿‡å¼•å…¥è®°å¿†å•å…ƒå’Œé—¨æœºåˆ¶ï¼ˆé—å¿˜é—¨ã€è¾“å…¥é—¨ã€è¾“å‡ºé—¨ï¼‰æ¥æ§åˆ¶ä¿¡æ¯ä¿ç•™å’Œä¸¢å¼ƒï¼Œä»è€Œè§£å†³äº† RNN çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚å®ƒæ“…é•¿å¤„ç†é•¿åºåˆ—ä¾èµ–ï¼Œæ¯”å¦‚æœºå™¨ç¿»è¯‘ã€è¯­éŸ³è¯†åˆ«ï¼Œä½†ç¼ºç‚¹æ˜¯ç»“æ„å¤æ‚ã€è®­ç»ƒé€Ÿåº¦æ…¢ï¼Œåæ¥é€æ¸è¢« Transformer å–ä»£ã€‚â€*



------



# GRU

![image-20250917095520316](assets/image-20250917095520316.png)

------

# ğŸš€ GRU ç®€å•æ€»ç»“

1. **å…¨ç§°**ï¼šGated Recurrent Unitï¼Œé—¨æ§å¾ªç¯å•å…ƒã€‚
   - æ˜¯ RNN çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œç”± Cho ç­‰äººåœ¨ 2014 å¹´æå‡ºã€‚
   - è®¾è®¡ç›®æ ‡ï¼š**ç®€åŒ– LSTM ç»“æ„**ï¼ŒåŒæ—¶è§£å†³ RNN çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
2. **æ ¸å¿ƒæ€æƒ³**ï¼š
   - é€šè¿‡ **é—¨æœºåˆ¶** æ§åˆ¶ä¿¡æ¯æµåŠ¨ï¼Œå†³å®šå“ªäº›è®°å¿†ä¿ç•™ï¼Œå“ªäº›ä¸¢å¼ƒã€‚
   - åªä¿ç•™ä¸¤ä¸ªé—¨ï¼š
     - **æ›´æ–°é—¨ï¼ˆupdate gateï¼‰**ï¼šå†³å®šä¿ç•™å¤šå°‘æ—§ä¿¡æ¯ã€å¼•å…¥å¤šå°‘æ–°ä¿¡æ¯ã€‚
     - **é‡ç½®é—¨ï¼ˆreset gateï¼‰**ï¼šå†³å®šé—å¿˜å¤šå°‘å†å²ä¿¡æ¯ï¼Œæ§åˆ¶å’Œå½“å‰è¾“å…¥çš„ç»“åˆã€‚
3. **ä¸ LSTM å¯¹æ¯”**ï¼š
   - LSTM æœ‰ **ä¸‰é—¨ + è®°å¿†å•å…ƒ**ï¼ˆè¾“å…¥ã€é—å¿˜ã€è¾“å‡º + cell stateï¼‰ã€‚
   - GRU **ä¸¤é—¨åˆä¸€ï¼Œæ— æ˜¾å¼è®°å¿†å•å…ƒ**ï¼Œç»“æ„æ›´ç®€å•ï¼Œå‚æ•°æ›´å°‘ã€‚
   - æ•ˆæœç›¸è¿‘ï¼Œä½† GRU è®­ç»ƒæ›´å¿«ã€èµ„æºå ç”¨æ›´å°ã€‚
4. **ä¼˜ç‚¹**ï¼š
   - èƒ½å»ºæ¨¡é•¿ä¾èµ–å…³ç³»ã€‚
   - è®­ç»ƒé€Ÿåº¦å¿«ï¼Œå‚æ•°æ›´å°‘ã€‚
   - åœ¨å°æ•°æ®é›†æˆ–è®¡ç®—èµ„æºæœ‰é™æ—¶å¸¸ä¼˜äº LSTMã€‚
5. **ç¼ºç‚¹**ï¼š
   - ç¼ºå°‘å•ç‹¬çš„è®°å¿†å•å…ƒï¼ˆcell stateï¼‰ï¼Œè¡¨è¾¾èƒ½åŠ›ç¨å¼±äº LSTMã€‚
   - åœ¨æŸäº›å¤æ‚ä»»åŠ¡ä¸Šæ•ˆæœä¸å¦‚ LSTM ç¨³å®šã€‚

------

# é¢è¯•é€Ÿç­”æ¨¡æ¿

*â€œGRU æ˜¯é—¨æ§å¾ªç¯å•å…ƒï¼Œæ˜¯å¯¹ RNN çš„æ”¹è¿›ã€‚å®ƒç”¨æ›´æ–°é—¨å’Œé‡ç½®é—¨æ¥æ§åˆ¶ä¿¡æ¯æµåŠ¨ï¼Œè§£å†³äº†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚ç›¸æ¯” LSTMï¼ŒGRU ç»“æ„æ›´ç®€å•ï¼Œæ²¡æœ‰å•ç‹¬çš„è®°å¿†å•å…ƒï¼Œå‚æ•°æ›´å°‘ï¼Œè®­ç»ƒæ›´å¿«ã€‚åœ¨å¾ˆå¤šä»»åŠ¡ä¸Šæ€§èƒ½æ¥è¿‘ LSTMï¼Œä½†åœ¨ä¸€äº›å¤æ‚ä»»åŠ¡ä¸­å¯èƒ½ç¨é€Šã€‚â€*



> - å·¥ç¨‹å¸¸ç”¨ç‰ˆï¼š`GRUClassifier`ï¼ˆåŸºäº `nn.GRU`ï¼‰ã€`LSTMClassifier`ï¼ˆåŸºäº `nn.LSTM`ï¼‰ï¼Œæ”¯æŒ `pack_padded_sequence` ä¸ `bidirectional`ã€‚
> - æ•™å­¦ç‰ˆï¼ˆæ‰‹å†™æ—¶é—´æ­¥å¾ªç¯ï¼‰ï¼š`SimpleGRUCellClassifier`ï¼ˆ`nn.GRUCell`ï¼‰ã€`SimpleLSTMCellClassifier`ï¼ˆ`nn.LSTMCell`ï¼‰ï¼Œé€æ­¥æ›´æ–°éšè—çŠ¶æ€å¹¶ç”¨ mask å±è”½ PADã€‚
>
> å¦‚ä½•åˆ‡æ¢ï¼š
>
> - åœ¨ä»£ç  `main()` é‡Œæ”¹ `hp.rnn_type` ä¸º `"rnn" | "gru" | "lstm"`ã€‚
> - å°† `hp.use_custom_cell = True` å¯åˆ‡åˆ°é€æ—¶é—´æ­¥æ•™å­¦å®ç°ï¼›`False` ä¸ºå·¥ç¨‹é«˜æ•ˆå®ç°ã€‚
> - éœ€è¦åŒå‘ç½‘ç»œå°±æŠŠ `hp.bidirectional = True`ï¼ˆä»…å·¥ç¨‹ç‰ˆæ”¯æŒï¼‰ã€‚
>
> è¿˜è¦ä¸è¦æˆ‘åŠ ä¸€ä¸ª**è¯­è¨€å»ºæ¨¡ï¼ˆmany-to-manyï¼‰\**çš„å°ä¾‹å­ï¼Œæˆ–æŠŠä¸‰ç§ç½‘ç»œçš„\**å†…éƒ¨é—¨æ§å…¬å¼æ¨å¯¼**ä¹Ÿæ³¨é‡Šè¿›å»ï¼Ÿ

```python
"""
Minimal RNN/GRU/LSTM in PyTorchï¼ˆå«è¶…è¯¦ç»†ä¸­æ–‡æ³¨é‡Šï¼‰
=================================================
ç›®æ ‡ï¼š
1) ä» 0 åˆ° 1 è·‘é€š **RNN / GRU / LSTM** ä¸‰ç§å¾ªç¯ç½‘ç»œåœ¨ä¸€ä¸ªåºåˆ—åˆ†ç±»ä»»åŠ¡ï¼ˆmany-to-oneï¼‰ä¸Šçš„å®ç°ã€‚
2) åŒæ—¶å±•ç¤ºä¸¤ç§å®ç°è·¯å¾„ï¼š
   (A) ç›´æ¥ä½¿ç”¨ `nn.RNN` / `nn.GRU` / `nn.LSTM`ï¼ˆå·¥ç¨‹å¸¸ç”¨ï¼‰
   (B) ä½¿ç”¨ `nn.RNNCell` / `nn.GRUCell` / `nn.LSTMCell` æ‰‹å†™æ—¶é—´æ­¥å¾ªç¯ï¼ˆå¸®åŠ©ç†è§£å†…éƒ¨è®¡ç®—ä¸éšè—çŠ¶æ€ç®¡ç†ï¼‰
3) è¦†ç›–ï¼šEmbeddingã€å¯å˜é•¿åºåˆ— paddingã€`pack_padded_sequence`ã€å–æœ€åæœ‰æ•ˆéšçŠ¶æ€ã€è®­ç»ƒ/è¯„ä¼°å¾ªç¯ã€‚

è¿è¡Œï¼š
$ python Minimal_RNN_PyTorch_Chinese_Comments.py
ï¼ˆå°†ä¸‹æ–¹æ–‡ä»¶ä¿å­˜ä¸ºåŒå .py åè¿è¡Œï¼›æ”¯æŒ CPU/GPUï¼‰

ç¯å¢ƒï¼šPyTorch>=1.12ï¼ˆæˆ– 2.xï¼‰ã€‚
"""
from __future__ import annotations
import random
from dataclasses import dataclass
from typing import List, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence

# ===============================
# 0) éšæœºç§å­ï¼Œä¾¿äºå¤ç°
# ===============================
def set_seed(seed: int = 42):
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

set_seed(42)

# ===============================
# 1) äººå·¥æ•°æ®é›†ï¼š
#    - è¯è¡¨ï¼šæ•´æ•° tokenï¼ˆ2..V-1ï¼‰ï¼Œ0 ç”¨ä½œ PADï¼ˆ1 å¯é¢„ç•™ä½œç‰¹æ®Šç¬¦å·ï¼‰ã€‚
#    - æ¯ä¸ªæ ·æœ¬æ˜¯ä¸€æ®µå¯å˜é•¿åºåˆ—ï¼Œæ ‡ç­¾ä¸ºâ€œåºåˆ—ä¸­ token ä¹‹å’Œçš„å¥‡å¶æ€§â€ï¼ˆsum%2ï¼‰ã€‚
#      è¿™æ˜¯ä¸€ä¸ªç©å…·äºŒåˆ†ç±»é—®é¢˜ï¼Œç”¨æ¥æ¼”ç¤º RNN/GRU/LSTM çš„å®Œæ•´è®­ç»ƒæµç¨‹ã€‚
# ===============================
class ToyVarLenParityDataset(Dataset):
    def __init__(self, num_samples: int, vocab_size: int = 100, min_len: int = 4, max_len: int = 20):
        self.vocab_size = vocab_size
        self.samples: List[Tuple[torch.LongTensor, int]] = []
        for _ in range(num_samples):
            L = random.randint(min_len, max_len)
            # å–å€¼èŒƒå›´é¿å¼€ 0ï¼ˆPADï¼‰ï¼Œæ­¤å¤„ 2..(vocab_size-1)
            seq = torch.randint(low=2, high=vocab_size, size=(L,), dtype=torch.long)
            label = int(seq.sum().item() % 2)  # 0 å¶æ•°ï¼Œ1 å¥‡æ•°
            self.samples.append((seq, label))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        return self.samples[idx]

# ===============================
# 2) collate_fnï¼š
#    - å°†ä¸€ä¸ª batch çš„å¯å˜é•¿åºåˆ—å¯¹é½ï¼ˆå³ä¾§ paddingï¼‰ï¼›
#    - è®°å½•æ¯ä¸ªåºåˆ—çš„çœŸå®é•¿åº¦ï¼ˆç”¨äº packï¼‰ã€‚
#    - è¿”å›ï¼špadded_seqs [B, L_max]ï¼Œlengths [B]ï¼Œlabels [B]
# ===============================
PAD_ID = 0

def collate_varlen(batch: List[Tuple[torch.LongTensor, int]]):
    seqs, labels = zip(*batch)  # seqs: Tuple[Tensor(L_i)], labels: Tuple[int]
    lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)
    # å³ä¾§ paddingï¼›æ³¨æ„ batch_first=True æ—¶ï¼ŒæœŸæœ› [B, L]
    padded = pad_sequence(seqs, batch_first=True, padding_value=PAD_ID)
    labels = torch.tensor(labels, dtype=torch.long)
    return padded, lengths, labels

# ===============================
# 3) ä¸‰ç§ç½‘ç»œçš„â€œæ¨¡å—åŒ–åˆ†ç±»å™¨â€ï¼ˆå·¥ç¨‹å¸¸ç”¨ç‰ˆæœ¬ï¼‰
#    å…±åŒç‚¹ï¼šEmbedding -> RNN/GRU/LSTM(Packed) -> å–æœ€åå±‚çš„æœ€åéšçŠ¶æ€ -> Linear
#    åŒºåˆ«ï¼š
#       - RNN/GRU è¿”å› (output, h_n)
#       - LSTM è¿”å› (output, (h_n, c_n))ï¼Œå…¶ä¸­ h_n æ˜¯æˆ‘ä»¬è¦ç”¨çš„â€œéšçŠ¶æ€â€
#    åŒå‘æ—¶ï¼ˆbidirectional=Trueï¼‰ï¼Œéœ€è¦æ‹¼æ¥åŒä¸€å±‚çš„æ­£å‘/åå‘ä¸¤ä¸ªæ–¹å‘çš„ h_nã€‚
# ===============================
class RNNClassifier(nn.Module):
    def __init__(self, vocab_size: int, emb_dim: int = 64, hidden_size: int = 128, num_layers: int = 1, bidirectional: bool = False):
        super().__init__()
        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)
        self.rnn = nn.RNN(
            input_size=emb_dim,
            hidden_size=hidden_size,
            num_layers=num_layers,
            nonlinearity='tanh',  # å¯é€‰ 'relu'
            batch_first=True,
            bidirectional=bidirectional,
        )
        self.bidirectional = bidirectional
        out_dim = hidden_size * (2 if bidirectional else 1)
        self.fc = nn.Linear(out_dim, 2)  # äºŒåˆ†ç±»

    def forward(self, input_ids: torch.LongTensor, lengths: torch.LongTensor):
        x = self.emb(input_ids)  # [B, L, E]
        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)
        _, h_n = self.rnn(packed)  # h_n: [num_layers*num_directions, B, H]
        if self.bidirectional:
            last_fwd = h_n[-2, :, :]  # [B, H]
            last_bwd = h_n[-1, :, :]  # [B, H]
            h = torch.cat([last_fwd, last_bwd], dim=-1)  # [B, 2H]
        else:
            h = h_n[-1, :, :]  # [B, H]
        logits = self.fc(h)
        return logits

class GRUClassifier(nn.Module):
    def __init__(self, vocab_size: int, emb_dim: int = 64, hidden_size: int = 128, num_layers: int = 1, bidirectional: bool = False):
        super().__init__()
        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)
        self.gru = nn.GRU(
            input_size=emb_dim,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            bidirectional=bidirectional,
        )
        self.bidirectional = bidirectional
        out_dim = hidden_size * (2 if bidirectional else 1)
        self.fc = nn.Linear(out_dim, 2)

    def forward(self, input_ids: torch.LongTensor, lengths: torch.LongTensor):
        x = self.emb(input_ids)
        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)
        _, h_n = self.gru(packed)  # [num_layers*num_directions, B, H]
        if self.bidirectional:
            h = torch.cat([h_n[-2], h_n[-1]], dim=-1)  # [B, 2H]
        else:
            h = h_n[-1]
        logits = self.fc(h)
        return logits

class LSTMClassifier(nn.Module):
    def __init__(self, vocab_size: int, emb_dim: int = 64, hidden_size: int = 128, num_layers: int = 1, bidirectional: bool = False):
        super().__init__()
        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)
        self.lstm = nn.LSTM(
            input_size=emb_dim,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            bidirectional=bidirectional,
        )
        self.bidirectional = bidirectional
        out_dim = hidden_size * (2 if bidirectional else 1)
        self.fc = nn.Linear(out_dim, 2)

    def forward(self, input_ids: torch.LongTensor, lengths: torch.LongTensor):
        x = self.emb(input_ids)
        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)
        _, (h_n, c_n) = self.lstm(packed)  # h_n/c_n: [num_layers*num_directions, B, H]
        if self.bidirectional:
            h = torch.cat([h_n[-2], h_n[-1]], dim=-1)
        else:
            h = h_n[-1]
        logits = self.fc(h)
        return logits

# ===============================
# 4) æ‰‹å†™æ—¶é—´æ­¥å¾ªç¯ï¼ˆæ•™å­¦ç‰ˆï¼‰ï¼šä½¿ç”¨ *_Cell å•å…ƒé€æ­¥æ›´æ–°
#    è¯´æ˜ï¼š
#      - è¿™é‡Œç”¨ PyTorch è‡ªå¸¦çš„ nn.RNNCell/GRUCell/LSTMCellï¼Œé€æ—¶é—´æ­¥å¾ªç¯ï¼Œ
#        å¹¶é…åˆ mask ä¿è¯è¶…è¿‡çœŸå®é•¿åº¦çš„ä½ç½®ä¸å†æ›´æ–°éšè—çŠ¶æ€ã€‚
#      - çœŸå®å·¥ç¨‹ï¼šå»ºè®®ä¼˜å…ˆç”¨ä¸Šé¢çš„æ¨¡å—åŒ–ç‰ˆæœ¬ + packï¼Œæ•ˆç‡æ›´é«˜ã€‚
# ===============================
class SimpleRNNCellClassifier(nn.Module):
    def __init__(self, vocab_size: int, emb_dim: int = 64, hidden_size: int = 128):
        super().__init__()
        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)
        self.cell = nn.RNNCell(emb_dim, hidden_size, nonlinearity='tanh')
        self.fc = nn.Linear(hidden_size, 2)

    def forward(self, input_ids: torch.LongTensor, lengths: torch.LongTensor):
        x = self.emb(input_ids)             # [B, L, E]
        B, L, E = x.shape
        H = self.cell.hidden_size
        h = x.new_zeros((B, H))            # h_0 = 0
        for t in range(L):
            x_t = x[:, t, :]                # [B, E]
            h_t = self.cell(x_t, h)         # [B, H]
            mask = (t < lengths).float().unsqueeze(-1)  # [B,1]
            h = h_t * mask + h * (1 - mask)            # ä»…å¯¹æœ‰æ•ˆæ ·æœ¬æ›´æ–°
        logits = self.fc(h)
        return logits

class SimpleGRUCellClassifier(nn.Module):
    def __init__(self, vocab_size: int, emb_dim: int = 64, hidden_size: int = 128):
        super().__init__()
        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)
        self.cell = nn.GRUCell(emb_dim, hidden_size)
        self.fc = nn.Linear(hidden_size, 2)

    def forward(self, input_ids: torch.LongTensor, lengths: torch.LongTensor):
        x = self.emb(input_ids)
        B, L, _ = x.shape
        H = self.cell.hidden_size
        h = x.new_zeros((B, H))
        for t in range(L):
            h_t = self.cell(x[:, t, :], h)
            mask = (t < lengths).float().unsqueeze(-1)
            h = h_t * mask + h * (1 - mask)
        logits = self.fc(h)
        return logits

class SimpleLSTMCellClassifier(nn.Module):
    def __init__(self, vocab_size: int, emb_dim: int = 64, hidden_size: int = 128):
        super().__init__()
        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)
        self.cell = nn.LSTMCell(emb_dim, hidden_size)
        self.fc = nn.Linear(hidden_size, 2)

    def forward(self, input_ids: torch.LongTensor, lengths: torch.LongTensor):
        x = self.emb(input_ids)
        B, L, _ = x.shape
        H = self.cell.hidden_size
        h = x.new_zeros((B, H))  # éšçŠ¶æ€ h
        c = x.new_zeros((B, H))  # è®°å¿†å•å…ƒ c
        for t in range(L):
            h_t, c_t = self.cell(x[:, t, :], (h, c))
            mask = (t < lengths).float().unsqueeze(-1)
            h = h_t * mask + h * (1 - mask)
            c = c_t * mask + c * (1 - mask)
        logits = self.fc(h)
        return logits

# ===============================
# 5) è®­ç»ƒä¸è¯„ä¼°æµç¨‹ï¼ˆé€šç”¨ï¼‰
# ===============================
@dataclass
class HParams:
    vocab_size: int = 200
    emb_dim: int = 64
    hidden_size: int = 128
    batch_size: int = 32
    lr: float = 1e-3
    epochs: int = 3
    rnn_type: str = "rnn"         # å¯é€‰: "rnn" | "gru" | "lstm"
    use_custom_cell: bool = False  # False: ç”¨æ¨¡å—åŒ–ç‰ˆæœ¬ï¼›True: ç”¨ *_Cell æ•™å­¦ç‰ˆ
    bidirectional: bool = False    # ä»…æ¨¡å—åŒ–ç‰ˆæœ¬æ”¯æŒ


def train_loop(model: nn.Module, loader: DataLoader, optimizer: torch.optim.Optimizer, device: torch.device):
    model.train()
    total_loss, total_correct, total = 0.0, 0, 0
    for input_ids, lengths, labels in loader:
        input_ids = input_ids.to(device)
        lengths = lengths.to(device)
        labels = labels.to(device)

        logits = model(input_ids, lengths)   # [B,2]
        loss = F.cross_entropy(logits, labels)

        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        optimizer.step()

        with torch.no_grad():
            pred = logits.argmax(dim=-1)
            total_correct += (pred == labels).sum().item()
            total += labels.size(0)
            total_loss += loss.item() * labels.size(0)
    return total_loss / total, total_correct / total


def eval_loop(model: nn.Module, loader: DataLoader, device: torch.device):
    model.eval()
    total_loss, total_correct, total = 0.0, 0, 0
    with torch.no_grad():
        for input_ids, lengths, labels in loader:
            input_ids = input_ids.to(device)
            lengths = lengths.to(device)
            labels = labels.to(device)
            logits = model(input_ids, lengths)
            loss = F.cross_entropy(logits, labels)
            pred = logits.argmax(dim=-1)
            total_correct += (pred == labels).sum().item()
            total += labels.size(0)
            total_loss += loss.item() * labels.size(0)
    return total_loss / total, total_correct / total

# ===============================
# 6) mainï¼šç»„è£…æ•°æ®ã€æ¨¡å‹ã€è®­ç»ƒ
# ===============================

def build_model(hp: HParams) -> nn.Module:
    if hp.use_custom_cell:
        # æ•™å­¦ç‰ˆï¼ˆé€æ—¶é—´æ­¥å¾ªç¯ï¼‰
        if hp.rnn_type == "rnn":
            return SimpleRNNCellClassifier(hp.vocab_size, hp.emb_dim, hp.hidden_size)
        elif hp.rnn_type == "gru":
            return SimpleGRUCellClassifier(hp.vocab_size, hp.emb_dim, hp.hidden_size)
        elif hp.rnn_type == "lstm":
            return SimpleLSTMCellClassifier(hp.vocab_size, hp.emb_dim, hp.hidden_size)
        else:
            raise ValueError("rnn_type åªèƒ½æ˜¯ rnn/gru/lstm")
    else:
        # å·¥ç¨‹ç‰ˆï¼ˆæ‰“åŒ…åºåˆ— + é«˜æ•ˆè®¡ç®—ï¼‰
        if hp.rnn_type == "rnn":
            return RNNClassifier(hp.vocab_size, hp.emb_dim, hp.hidden_size, num_layers=1, bidirectional=hp.bidirectional)
        elif hp.rnn_type == "gru":
            return GRUClassifier(hp.vocab_size, hp.emb_dim, hp.hidden_size, num_layers=1, bidirectional=hp.bidirectional)
        elif hp.rnn_type == "lstm":
            return LSTMClassifier(hp.vocab_size, hp.emb_dim, hp.hidden_size, num_layers=1, bidirectional=hp.bidirectional)
        else:
            raise ValueError("rnn_type åªèƒ½æ˜¯ rnn/gru/lstm")


def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    hp = HParams()
    # ============ æ ¹æ®éœ€è¦åœ¨æ­¤ä¿®æ”¹ ============
    # hp.rnn_type = "gru"       # åˆ‡æ¢ä¸º GRU
    # hp.rnn_type = "lstm"      # åˆ‡æ¢ä¸º LSTM
    # hp.use_custom_cell = True  # åˆ‡æ¢åˆ° *_Cell æ•™å­¦ç‰ˆå®ç°
    # hp.bidirectional = True    # ä»…æ¨¡å—åŒ–ç‰ˆæœ¬æ”¯æŒåŒå‘
    # =========================================

    # æ•°æ®ï¼šè®­ç»ƒ/éªŒè¯
    train_ds = ToyVarLenParityDataset(num_samples=2000, vocab_size=hp.vocab_size)
    valid_ds = ToyVarLenParityDataset(num_samples=400, vocab_size=hp.vocab_size)
    train_loader = DataLoader(train_ds, batch_size=hp.batch_size, shuffle=True, collate_fn=collate_varlen)
    valid_loader = DataLoader(valid_ds, batch_size=hp.batch_size, shuffle=False, collate_fn=collate_varlen)

    # æ„å»ºæ¨¡å‹
    model = build_model(hp).to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=hp.lr)

    # è®­ç»ƒè‹¥å¹²ä¸ª epoch
    for epoch in range(1, hp.epochs + 1):
        tr_loss, tr_acc = train_loop(model, train_loader, optimizer, device)
        va_loss, va_acc = eval_loop(model, valid_loader, device)
        print(f"Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | valid loss {va_loss:.4f} acc {va_acc:.4f}")

    # æ¼”ç¤ºï¼šå•æ¡æ ·æœ¬é¢„æµ‹
    model.eval()
    with torch.no_grad():
        seq = torch.tensor([5, 7, 9, 4, 3, 8])  # ä¾‹å­åºåˆ—
        label = int(seq.sum().item() % 2)
        input_ids, lengths, _ = collate_varlen([(seq, label)])
        logits = model(input_ids.to(device), lengths.to(device))
        prob = logits.softmax(-1)[0]
        pred = prob.argmax().item()
        print(f"æµ‹è¯•æ ·æœ¬: {seq.tolist()} | çœŸå€¼(å¥‡å¶)={label} | é¢„æµ‹={pred} | æ¦‚ç‡={prob.cpu().tolist()}")


if __name__ == '__main__':
    main()

```





# Transformer

![img](assets/Transformer%2C_full_architecture.png)

------

# ğŸš€Transformer 

**æ•´ä½“ç»“æ„ï¼šEncoderâ€“Decoder**

- **è¾“å…¥**ï¼šè¯å‘é‡ + ä½ç½®ç¼–ç 
- **Encoder**ï¼šå †å  N å±‚ï¼ˆå¸¸è§ 6 å±‚ï¼‰ â†’ æ¯å±‚åŒ…å«
  1. **å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼ˆMulti-Head Self-Attentionï¼‰**ï¼šæ•æ‰å¥å­å†…éƒ¨å„è¯ä¹‹é—´å…³ç³»
  2. **å‰é¦ˆå…¨è¿æ¥ç½‘ç»œï¼ˆFFNï¼‰**ï¼šæå‡éçº¿æ€§è¡¨è¾¾èƒ½åŠ›
  3. **æ®‹å·®è¿æ¥ + LayerNorm**ï¼šé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±ï¼ŒåŠ å¿«æ”¶æ•›
- **Decoder**ï¼šç»“æ„ç±»ä¼¼ï¼Œä½†å¤šäº†
  1. **Masked Self-Attention**ï¼šä¿è¯åªçœ‹è§å†å²ä¿¡æ¯
  2. **Encoderâ€“Decoder Attention**ï¼šæŠŠç¼–ç å™¨çš„ä¿¡æ¯å¼•å…¥è§£ç å™¨
- **è¾“å‡º**ï¼šé€šè¿‡ Softmax å¾—åˆ°é¢„æµ‹ç»“æœï¼ˆå¦‚ä¸‹ä¸€ä¸ªè¯æ¦‚ç‡åˆ†å¸ƒï¼‰ã€‚

------

# æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

1. **è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰**
   - å…¬å¼ï¼š`Attention(Q,K,V) = softmax(QK^T / âˆšd_k) V`
   - ä½œç”¨ï¼šè¡¡é‡è¯ä¸è¯çš„ç›¸å…³æ€§ã€‚
2. **å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰**
   - å¤šç»„ Q/K/V å¹¶è¡Œè®¡ç®—ï¼Œèƒ½å…³æ³¨ä¸åŒè¯­ä¹‰å…³ç³»ã€‚
3. **ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰**
   - å› ä¸ºæ²¡æœ‰å¾ªç¯å’Œå·ç§¯ï¼Œæ‰€ä»¥ç”¨ä½ç½®ç¼–ç è®©æ¨¡å‹çŸ¥é“è¯çš„é¡ºåºã€‚
4. **å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰**
   - ä¸¤å±‚çº¿æ€§å˜æ¢ + æ¿€æ´»å‡½æ•°ï¼ˆReLU/GELUï¼‰ã€‚
5. **æ®‹å·®è¿æ¥ + LayerNorm**
   - ç¨³å®šè®­ç»ƒã€æé«˜æ¢¯åº¦ä¼ æ’­ã€‚
6. **ä¸‰ç§å¸¸è§æ¶æ„**
   - **Encoder-only**ï¼ˆBERTï¼‰ï¼šç†è§£ä»»åŠ¡ï¼ˆåˆ†ç±»/æ£€ç´¢ï¼‰ã€‚
   - **Decoder-only**ï¼ˆGPTï¼‰ï¼šç”Ÿæˆä»»åŠ¡ï¼ˆå¯¹è¯/å†™ä½œï¼‰ã€‚
   - **Encoderâ€“Decoder**ï¼ˆåŸå§‹ Transformer, T5ï¼‰ï¼šåºåˆ—åˆ°åºåˆ—ï¼ˆç¿»è¯‘/æ‘˜è¦ï¼‰ã€‚
7. **ä¼˜åŠ¿**
   - å¹¶è¡Œè®­ç»ƒ â†’ é€Ÿåº¦å¿«ã€‚
   - é•¿ä¾èµ–å»ºæ¨¡èƒ½åŠ›å¼ºã€‚
   - å¯æ‰©å±•åˆ°å¤šæ¨¡æ€ï¼ˆå›¾åƒ/è¯­éŸ³/è·¨æ¨¡æ€ï¼‰ã€‚

------

è¦æ˜¯é¢è¯•å®˜é—®â€œTransformer çš„åŸºæœ¬åŸç†â€ï¼Œä½ å¯ä»¥ç®€çŸ­å›ç­”ï¼š
 ğŸ‘‰ *â€œTransformer ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ä»£æ›¿ RNN/CNN å»ºæ¨¡åºåˆ—å…³ç³»ï¼Œé€šè¿‡å¤šå¤´æ³¨æ„åŠ›æ•æ‰ä¸åŒè¯­ä¹‰ï¼Œä½ç½®ç¼–ç è¡¥å……é¡ºåºä¿¡æ¯ï¼Œæ•´ä¸ªç»“æ„é æ®‹å·®å’Œå½’ä¸€åŒ–ä¿è¯ç¨³å®šã€‚Encoder ä¸»è¦åšç†è§£ï¼ŒDecoder ä¸»è¦åšç”Ÿæˆã€‚â€*







å¥½é—®é¢˜ ğŸ‘Œ è¿™æ˜¯é¢è¯•é‡Œæœ€å¸¸è¢«è¿½é—®çš„ç»†èŠ‚ä¹‹ä¸€ã€‚ä¸‹é¢æˆ‘ç»™ä½ ç”¨**ç›´ç™½ç±»æ¯” + æ•°å­¦è§£é‡Š**ä¸¤ç§æ–¹å¼è®²æ¸…æ¥š Qã€Kã€Vï¼š

------

# 1. ç›´è§‚ç†è§£ï¼ˆç±»æ¯”ç‰ˆï¼‰

- **Q (Query, æŸ¥è¯¢)**ï¼šæˆ‘æ˜¯è°ï¼Œè¦å»æ‰¾ç›¸å…³ä¿¡æ¯ã€‚
- **K (Key, é”®)**ï¼šæˆ‘çš„ç‰¹å¾æ ‡ç­¾ï¼Œç”¨æ¥åŒ¹é…åˆ«äººã€‚
- **V (Value, å€¼)**ï¼šæˆ‘çš„å®é™…å†…å®¹ï¼Œè¢«å–å‡ºæ¥åŠ æƒç»„åˆã€‚

ğŸ‘‰ ç±»æ¯”ï¼š
 ä½ åœ¨å›¾ä¹¦é¦†æ‰¾ä¹¦ã€‚

- ä½ çš„é—®é¢˜å°±æ˜¯ **Q**ã€‚
- æ¯æœ¬ä¹¦çš„æ ‡ç­¾ï¼ˆæ ‡é¢˜/åˆ†ç±»å·ï¼‰å°±æ˜¯ **K**ã€‚
- ä¹¦çš„å†…å®¹å°±æ˜¯ **V**ã€‚
   è®¡ç®— Q å’Œ K çš„ç›¸ä¼¼åº¦ï¼ˆç›¸å…³æ€§ï¼‰ï¼Œå†æ ¹æ®ç»“æœå†³å®šä»å“ªäº› V æ‹¿å¤šå°‘å†…å®¹ã€‚

------

# 2. æ•°å­¦è§£é‡Š

![image-20250917093219126](assets/image-20250917093219126.png)

------

# 3. ä½œç”¨æ€»ç»“

- **Q**ï¼šå†³å®šâ€œæˆ‘è¦æ‰¾ä»€ä¹ˆä¿¡æ¯â€ã€‚
- **K**ï¼šå†³å®šâ€œæˆ‘èƒ½æä¾›ä»€ä¹ˆä¿¡æ¯â€ã€‚
- **V**ï¼šçœŸæ­£â€œæä¾›çš„ä¿¡æ¯å†…å®¹â€ã€‚

------

å¦‚æœé¢è¯•å®˜çªç„¶é—®ï¼š
 ğŸ‘‰ **â€œQã€Kã€V ä¸ºä»€ä¹ˆè¦åˆ†å¼€å­¦ï¼Œä¸ç›´æ¥ç”¨ Xï¼Ÿâ€**
 ä½ å¯ä»¥ç­”ï¼š

- ä¸åŒçš„ä»»åŠ¡éœ€è¦ä¸åŒçš„è¡¨ç¤ºç©ºé—´ï¼ŒQ/K/V æŠ•å½±è®©æ¨¡å‹èƒ½å­¦åˆ°**ä¸åŒè§’åº¦çš„ç‰¹å¾**ã€‚
- ä¾‹å¦‚ Q/K ä¸“æ³¨åŒ¹é…å…³ç³»ï¼ŒV ä¸“æ³¨æºå¸¦ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
- åˆ†å¼€è¿˜èƒ½å¢åŠ æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚



```python
"""
Minimal Transformer (Encoder-Decoder) from scratch in PyTorch
=============================================================
ç›®æ ‡ï¼ˆä¸ºé…åˆé¢è¯•/å­¦ä¹ ï¼ŒåŠ å…¥**è¶…è¯¦ç»†ä¸­æ–‡æ³¨é‡Š**ï¼‰ï¼š
1) é€è¡Œå¯¹åº”æŠ½è±¡æ¶æ„å›¾ï¼ˆä½ç½®ç¼–ç  â†’ å¤šå¤´æ³¨æ„åŠ› â†’ å‰é¦ˆç½‘ç»œ â†’ æ®‹å·®/å½’ä¸€åŒ– â†’ ç¼–è§£ç å †å ï¼‰ã€‚
2) æ˜¾å¼æ ‡æ³¨**å¼ é‡å½¢çŠ¶**å’Œ**mask è¯­ä¹‰**ï¼ˆ1=ä¿ç•™ã€0=é®æŒ¡ï¼‰ï¼Œé¿å…â€œè„‘è¡¥â€ã€‚
3) é™„å¸¦ä¸€ä¸ª**å¯è¿è¡Œçš„æç®€ Demo**ï¼ˆtoy copy taskï¼‰ï¼Œè§‚å¯Ÿå‰å‘/æŸå¤±/ä¸€æ­¥è®­ç»ƒï¼Œå¸®åŠ©ç†è§£æ•°æ®æµã€‚

ä½ å¯ä»¥è¿è¡Œï¼š
$ python Minimal_Transformer_PyTorch.py

ä¾èµ–ï¼šPyTorch >= 1.12ï¼ˆæˆ– 2.xï¼‰ã€‚CPU ä¹Ÿå¯è¿è¡Œã€‚
"""
from __future__ import annotations
import math
from dataclasses import dataclass
from typing import Optional, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F

# ===================================================================
# 1) ä½ç½®ç¼–ç ï¼ˆPositional Encoding, Sin/Cosï¼‰
# -------------------------------------------------------------------
# Transformer ä¸å«å¾ªç¯/å·ç§¯ï¼Œæ¨¡å‹æœ¬èº«ä¸çŸ¥é“â€œé¡ºåºâ€ã€‚
# å› æ­¤éœ€è¦æ˜¾å¼æ³¨å…¥ä½ç½®ä¿¡æ¯ï¼šæœ€ç»å…¸çš„æ˜¯â€œæ­£å¼¦/ä½™å¼¦ä½ç½®ç¼–ç â€ã€‚
# ç‰¹ç‚¹ï¼š
# - æ— å‚æ•°ï¼›
# - å¯¹ä¸åŒé•¿åº¦å¯æ’å€¼ï¼›
# - é«˜é¢‘/ä½é¢‘ç»„åˆï¼Œèƒ½è¡¨è¾¾ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚
# ===================================================================
class PositionalEncoding(nn.Module):
    """æ­£å¼¦/ä½™å¼¦ä½ç½®ç¼–ç ï¼ˆä¸åŸè®ºæ–‡ä¸€è‡´ï¼‰
    è¾“å…¥ï¼šåµŒå…¥åå¼ é‡ xï¼Œå½¢çŠ¶ [B, L, d_model]
    è¾“å‡ºï¼šx ä¸ä½ç½®ç¼–ç é€å…ƒç´ ç›¸åŠ åçš„å¼ é‡ï¼ˆå½¢çŠ¶ä¸å˜ï¼‰
    """
    def __init__(self, d_model: int, max_len: int = 10000):
        super().__init__()
        # pe: [max_len, d_model]ï¼Œä¸ºæ¯ä¸ªä½ç½®é¢„å…ˆç”Ÿæˆå›ºå®šçš„ç¼–ç 
        pe = torch.zeros(max_len, d_model)
        # position: [max_len, 1]ï¼Œä½ç½®ç´¢å¼• 0..max_len-1
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        # div_termï¼šé¢‘ç‡é¡¹ï¼Œå¶æ•°ç»´ç”¨ sinï¼Œå¥‡æ•°ç»´ç”¨ cos
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0)  # [1, max_len, d_model]ï¼Œæ–¹ä¾¿ä¸æ‰¹æ¬¡å¹¿æ’­ç›¸åŠ 
        # register_buffer è¡¨ç¤ºè¿™ä¸æ˜¯å¯è®­ç»ƒå‚æ•°ï¼Œä½†ä¼šéšæ¨¡å‹ä¿å­˜/åŠ è½½
        self.register_buffer('pe', pe)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x: [B, L, d_model]
        L = x.size(1)
        # æˆªå–å‰ L ä¸ªä½ç½®ç¼–ç å¹¶ç›¸åŠ 
        return x + self.pe[:, :L, :]


# ===================================================================
# 2) å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attention, MHAï¼‰
# -------------------------------------------------------------------
# æ ¸å¿ƒå…¬å¼ï¼šAttn(Q,K,V) = softmax(QK^T / sqrt(d_k)) V
# ç›´è§‰ï¼šç”¨ Query ä¸ Key çš„ç›¸ä¼¼åº¦ï¼ˆç›¸å…³æ€§ï¼‰å¯¹ Value åšåŠ æƒæ±‡èšã€‚
# å¤šå¤´ï¼šå°†ç‰¹å¾ç»´åˆ‡åˆ†ä¸º h ä¸ªå­ç©ºé—´å¹¶è¡Œè®¡ç®—ï¼Œæ•æ‰ä¸åŒå…³ç³»æ¨¡å¼ï¼›æœ€åæ‹¼æ¥ã€‚
# æœ¬å®ç°ï¼š
# - æ˜¾å¼ç»™å‡ºå½¢çŠ¶è½¬æ¢ï¼š [B, L, d] â†’ [B, h, L, d_head]
# - attn_mask: 1=ä¿ç•™, 0=é®æŒ¡ï¼ˆå…¼å®¹ padding mask / causal maskï¼‰
# ===================================================================
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model: int, num_heads: int, dropout: float = 0.0):
        super().__init__()
        assert d_model % num_heads == 0, "d_model å¿…é¡»èƒ½è¢« num_heads æ•´é™¤"
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_head = d_model // num_heads  # æ¯ä¸ªå¤´çš„ç»´åº¦

        # Q/K/V çš„çº¿æ€§æŠ•å½±ï¼šåˆ†åˆ«å­¦ä¹ ä¸åŒçš„è¡¨ç¤ºç©ºé—´
        self.w_q = nn.Linear(d_model, d_model)
        self.w_k = nn.Linear(d_model, d_model)
        self.w_v = nn.Linear(d_model, d_model)
        # å¤´æ‹¼æ¥åçš„è¾“å‡ºæŠ•å½±
        self.w_o = nn.Linear(d_model, d_model)
        self.dropout = nn.Dropout(dropout)

    def forward(
        self,
        q: torch.Tensor,  # [B, L_q, d_model]
        k: torch.Tensor,  # [B, L_k, d_model]
        v: torch.Tensor,  # [B, L_k, d_model]
        attn_mask: Optional[torch.Tensor] = None,  # [B,1,L_q,L_k] æˆ– [1,1,L_q,L_k]ï¼Œ1=ä¿ç•™ï¼Œ0=é®æŒ¡
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        B, L_q, _ = q.shape
        B, L_k, _ = k.shape

        # 2.1 çº¿æ€§æ˜ å°„åˆ° Q/K/V ç©ºé—´
        Q = self.w_q(q)  # [B, L_q, d_model]
        K = self.w_k(k)  # [B, L_k, d_model]
        V = self.w_v(v)  # [B, L_k, d_model]

        # 2.2 åˆ‡åˆ†å¤šå¤´å¹¶è°ƒæ•´ç»´åº¦é¡ºåºï¼š [B, L, h, d_head] â†’ [B, h, L, d_head]
        def split_heads(x):
            return x.view(B, -1, self.num_heads, self.d_head).transpose(1, 2)

        Q = split_heads(Q)  # [B, h, L_q, d_head]
        K = split_heads(K)  # [B, h, L_k, d_head]
        V = split_heads(V)  # [B, h, L_k, d_head]

        # 2.3 è®¡ç®—ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›åˆ†æ•°ï¼š [B,h,L_q,L_k]
        scores = Q @ K.transpose(-2, -1) / math.sqrt(self.d_head)
        # æ©ç ï¼šå°†ä¸å…è®¸çš„ä½ç½®ç½®ä¸º -infï¼Œä½¿ softmax åæ¦‚ç‡ä¸º 0
        if attn_mask is not None:
            scores = scores.masked_fill(attn_mask == 0, float('-inf'))
        attn = F.softmax(scores, dim=-1)  # æ³¨æ„åŠ›æƒé‡
        attn = self.dropout(attn)

        # 2.4 åŠ æƒæ±‚å’Œå¾—åˆ°ä¸Šä¸‹æ–‡ï¼Œåˆå¹¶å¤šå¤´
        context = attn @ V  # [B, h, L_q, d_head]
        context = context.transpose(1, 2).contiguous().view(B, L_q, self.d_model)  # [B, L_q, d_model]
        out = self.w_o(context)  # [B, L_q, d_model]
        return out, attn  # è¿”å› attn ä¾¿äºè°ƒè¯•/å¯è§†åŒ–


# ===================================================================
# 3) å‰é¦ˆç½‘ç»œï¼ˆFeed-Forward, FFNï¼‰
# -------------------------------------------------------------------
# é€ä½ç½®ï¼ˆposition-wiseï¼‰ä¸¤å±‚ MLPï¼Œé€šå¸¸éšè—ç»´åº¦æ”¾å¤§ 4Ã—ï¼ˆæ­¤å¤„ç”¨ d_ffï¼‰ã€‚
# æ¿€æ´»å¸¸è§ ReLU/GELU/SiLUï¼›æœ¬ä¾‹ä½¿ç”¨ GELUï¼Œè®­ç»ƒæ›´å¹³æ»‘ã€‚
# ===================================================================
class FeedForward(nn.Module):
    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.0):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.GELU(),              # éçº¿æ€§
            nn.Dropout(dropout),
            nn.Linear(d_ff, d_model),
            nn.Dropout(dropout),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x)


# ===================================================================
# 4) ç¼–ç å™¨å±‚ï¼ˆEncoder Layer, é‡‡ç”¨ Pre-LNï¼‰
# -------------------------------------------------------------------
# Pre-LNï¼šåœ¨å­å±‚å‰åš LayerNormï¼ˆå·¥ä¸šç•Œæ›´ç¨³ï¼Œæ˜“è®­ç»ƒæ·±å±‚ï¼‰ã€‚
# æµç¨‹ï¼šx â†’ LN â†’ è‡ªæ³¨æ„åŠ› â†’ æ®‹å·®ç›¸åŠ  â†’ LN â†’ FFN â†’ æ®‹å·®ç›¸åŠ 
# src_maskï¼šé€šå¸¸æ˜¯ padding maskï¼Œå½¢çŠ¶ [B,1,1,L_src]ï¼Œå¹¿æ’­åˆ°æ³¨æ„åŠ›åˆ†æ•°
# ===================================================================
class EncoderLayer(nn.Module):
    def __init__(self, d_model: int, num_heads: int, d_ff: int, dropout: float = 0.0):
        super().__init__()
        self.ln1 = nn.LayerNorm(d_model)
        self.attn = MultiHeadAttention(d_model, num_heads, dropout)
        self.ln2 = nn.LayerNorm(d_model)
        self.ffn = FeedForward(d_model, d_ff, dropout)

    def forward(self, x: torch.Tensor, src_mask: Optional[torch.Tensor]) -> torch.Tensor:
        # æ³¨æ„ï¼šä¸ºç®€æ´ï¼Œè¿™é‡Œå¯¹ ln1(x) é‡å¤è®¡ç®—äº†ä¸‰æ¬¡ï¼›
        # å·¥ç¨‹ä¸­å¯å†™æˆ tmp = self.ln1(x) å†å¤ç”¨ï¼Œç»“æœä¸€è‡´ã€‚
        y, _ = self.attn(self.ln1(x), self.ln1(x), self.ln1(x), attn_mask=src_mask)
        x = x + y  # æ®‹å·®
        z = self.ffn(self.ln2(x))
        x = x + z  # æ®‹å·®
        return x


# ===================================================================
# 5) è§£ç å™¨å±‚ï¼ˆDecoder Layer, Pre-LNï¼‰
# -------------------------------------------------------------------
# æ¯”ç¼–ç å™¨å¤šä¸¤ä¸ªç‚¹ï¼š
# - Masked Self-Attentionï¼šå› æœæ©ç ï¼Œä¿è¯è‡ªå›å½’åªçœ‹å†å²ï¼›
# - Cross-Attentionï¼šç”¨ç¼–ç å™¨è¾“å‡º memory åš K/Vï¼Œå°†æºä¿¡æ¯å¼•å…¥è§£ç è¿‡ç¨‹ã€‚
# tgt_maskï¼šå› æœ + å¡«å……ï¼›memory_maskï¼šå°† tgt ä¸ src çš„ padding å¯¹é½ã€‚
# ===================================================================
class DecoderLayer(nn.Module):
    def __init__(self, d_model: int, num_heads: int, d_ff: int, dropout: float = 0.0):
        super().__init__()
        self.ln1 = nn.LayerNorm(d_model)
        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)
        self.ln2 = nn.LayerNorm(d_model)
        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)
        self.ln3 = nn.LayerNorm(d_model)
        self.ffn = FeedForward(d_model, d_ff, dropout)

    def forward(
        self,
        x: torch.Tensor,              # è§£ç å™¨è¾“å…¥ [B, L_tgt, d]
        memory: torch.Tensor,         # ç¼–ç å™¨è¾“å‡º [B, L_src, d]
        tgt_mask: Optional[torch.Tensor],     # [B/1,1,L_tgt,L_tgt]
        memory_mask: Optional[torch.Tensor],  # [B,1,L_tgt,L_src]
    ) -> torch.Tensor:
        # 5.1 ç›®æ ‡åºåˆ—çš„**æ©ç è‡ªæ³¨æ„åŠ›**ï¼ˆåŒ…å«å› æœä¸Šä¸‰è§’é®æŒ¡ï¼‰
        y, _ = self.self_attn(self.ln1(x), self.ln1(x), self.ln1(x), attn_mask=tgt_mask)
        x = x + y
        # 5.2 ä¸ç¼–ç å™¨çš„**äº¤å‰æ³¨æ„åŠ›**ï¼ˆQ æ¥è‡ªè§£ç å™¨ï¼ŒK/V æ¥è‡ªç¼–ç å™¨ memoryï¼‰
        y, _ = self.cross_attn(self.ln2(x), memory, memory, attn_mask=memory_mask)
        x = x + y
        # 5.3 å‰é¦ˆç½‘ç»œ
        z = self.ffn(self.ln3(x))
        x = x + z
        return x


# ===================================================================
# 6) ç¼–ç å™¨/è§£ç å™¨å †å 
# -------------------------------------------------------------------
# - åµŒå…¥å±‚ï¼šå°† token id â†’ å‘é‡è¡¨ç¤ºï¼›
# - ä½ç½®ç¼–ç ï¼šæ³¨å…¥é¡ºåºï¼›
# - å¤šå±‚ Encoder/DecoderLayer å †å ï¼›
# - Decoder æœ«ç«¯é€šå¸¸å†æ¥ LayerNormï¼ˆç¨³å®šï¼‰ã€‚
# ===================================================================
class Encoder(nn.Module):
    def __init__(self, vocab_size: int, d_model: int, num_layers: int, num_heads: int, d_ff: int, dropout: float):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, d_model)
        self.pos = PositionalEncoding(d_model)
        self.layers = nn.ModuleList([
            EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)
        ])

    def forward(self, src_ids: torch.LongTensor, src_mask: Optional[torch.Tensor]):
        # src_ids: [B, L_src]
        x = self.embed(src_ids)  # [B, L_src, d]
        x = self.pos(x)
        for layer in self.layers:
            x = layer(x, src_mask)
        return x  # ä½œä¸º memory ä¾›è§£ç å™¨ä½¿ç”¨


class Decoder(nn.Module):
    def __init__(self, vocab_size: int, d_model: int, num_layers: int, num_heads: int, d_ff: int, dropout: float):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, d_model)
        self.pos = PositionalEncoding(d_model)
        self.layers = nn.ModuleList([
            DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)
        ])
        self.ln = nn.LayerNorm(d_model)

    def forward(
        self,
        tgt_ids: torch.LongTensor,
        memory: torch.Tensor,
        tgt_mask: Optional[torch.Tensor],
        memory_mask: Optional[torch.Tensor],
    ):
        x = self.embed(tgt_ids)  # [B, L_tgt, d]
        x = self.pos(x)
        for layer in self.layers:
            x = layer(x, memory, tgt_mask, memory_mask)
        return self.ln(x)


# ===================================================================
# 7) æ•´ä½“ Transformerï¼ˆEncoder-Decoderï¼‰
# -------------------------------------------------------------------
# forward æ¥å£ï¼š
# - è¾“å…¥ src_ids, tgt_idsï¼ˆè®­ç»ƒæ—¶å¸¸ç”¨â€œæ•™å¸ˆå¼ºåˆ¶â€ï¼Œå³ç»™å®šå·²çŸ¥ tgt å‰ç¼€é¢„æµ‹ä¸‹ä¸€ä¸ªï¼‰
# - æ„é€  padding mask ä¸ causal maskï¼›
# - è¾“å‡ºè¯è¡¨ logitsï¼ˆè¿˜æœª softmaxï¼‰ï¼Œå½¢çŠ¶ [B, L_tgt, vocab]
# ===================================================================
class Transformer(nn.Module):
    def __init__(
        self,
        src_vocab: int,
        tgt_vocab: int,
        d_model: int = 256,
        num_layers: int = 2,
        num_heads: int = 4,
        d_ff: int = 512,
        dropout: float = 0.1,
    ):
        super().__init__()
        self.encoder = Encoder(src_vocab, d_model, num_layers, num_heads, d_ff, dropout)
        self.decoder = Decoder(tgt_vocab, d_model, num_layers, num_heads, d_ff, dropout)
        # çº¿æ€§æ˜ å°„åˆ°è¯è¡¨ç»´åº¦ï¼Œå¾—åˆ°æ¯ä¸ªä½ç½®çš„åˆ†ç±» logits
        self.generator = nn.Linear(d_model, tgt_vocab)

    def forward(
        self,
        src_ids: torch.LongTensor,  # [B, L_src]
        tgt_ids: torch.LongTensor,  # [B, L_tgt]
        src_key_padding_mask: Optional[torch.Tensor] = None,  # [B,1,1,L_src]  1=ä¿ç•™,0=é®æŒ¡
        tgt_key_padding_mask: Optional[torch.Tensor] = None,  # [B,1,1,L_tgt]
    ) -> torch.Tensor:
        # 7.1 æ„é€ å„ç§ mask
        src_mask = src_key_padding_mask  # ç¼–ç å™¨è‡ªæ³¨æ„åŠ›ä½¿ç”¨
        causal = generate_square_subsequent_mask(tgt_ids.size(1), device=tgt_ids.device)  # å› æœæ©ç  [1,1,Lt,Lt]
        tgt_mask = combine_masks(causal, tgt_key_padding_mask)  # ç›®æ ‡åºåˆ—è‡ªæ³¨æ„åŠ›éœ€è¦â€œå› æœ + å¡«å……â€
        mem_mask = expand_kv_mask(tgt_len=tgt_ids.size(1), src_key_padding_mask=src_key_padding_mask)  # äº¤å‰æ³¨æ„åŠ›ä½¿ç”¨

        # 7.2 å‰å‘ï¼šç¼–ç  â†’ è§£ç  â†’ è¯è¡¨æŠ•å½±
        memory = self.encoder(src_ids, src_mask)           # [B, L_src, d]
        dec_out = self.decoder(tgt_ids, memory, tgt_mask, mem_mask)  # [B, L_tgt, d]
        logits = self.generator(dec_out)                   # [B, L_tgt, vocab]
        return logits


# ===================================================================
# 8) æ©ç å·¥å…·å‡½æ•°ï¼ˆmask helpersï¼‰
# -------------------------------------------------------------------
# ç»Ÿä¸€çº¦å®šï¼šmask ä¸­ 1=ä¿ç•™ï¼ˆå¯è§ï¼‰ï¼Œ0=é®æŒ¡ï¼ˆä¸å¯è§ï¼‰ã€‚
# - causal maskï¼šä¸Šä¸‰è§’ä¸º 0ï¼Œä¿è¯ä½ç½® i åªèƒ½çœ‹ <= i çš„ä¿¡æ¯ï¼›
# - padding maskï¼šå°† PAD ä½ç½®ç½® 0ï¼Œé˜²æ­¢æ— æ„ä¹‰ token å¹²æ‰°æ³¨æ„åŠ›ã€‚
# ===================================================================

def generate_square_subsequent_mask(L: int, device=None) -> torch.Tensor:
    """ç”Ÿæˆå› æœæ©ç ï¼ˆä¸¥æ ¼ä¸‹ä¸‰è§’ä¸º 1ï¼Œä¸Šä¸‰è§’ä¸º 0ï¼‰ã€‚
    è¿”å›å½¢çŠ¶ [1, 1, L, L]ï¼Œæ–¹ä¾¿ä¸æ‰¹æ¬¡/å¤´æ•°å¹¿æ’­ã€‚
    """
    mask = torch.tril(torch.ones(L, L, device=device)).unsqueeze(0).unsqueeze(0)
    return mask  # [1, 1, L, L]


def make_padding_mask(pad_mask_1d: torch.Tensor) -> torch.Tensor:
    """å°† [B, L]ï¼ˆ1=ä¿ç•™,0=PADï¼‰æ‰©å±•ä¸ºæ³¨æ„åŠ›éœ€è¦çš„ [B, 1, 1, L] å½¢çŠ¶ã€‚
    å…¸å‹è°ƒç”¨ï¼špad_mask_1d = (input_ids != pad_id)
    """
    return pad_mask_1d.unsqueeze(1).unsqueeze(2)  # [B, 1, 1, L]


def combine_masks(*masks: Optional[torch.Tensor]) -> Optional[torch.Tensor]:
    """å°†å¤šä¸ª mask ç”¨â€œä¸â€ç›¸ä¹˜åˆå¹¶ï¼ˆ1/0 ä¹˜æ³•ç­‰ä»·äºé€»è¾‘ä¸ï¼‰ã€‚
    å½¢çŠ¶éœ€å¯å¹¿æ’­ï¼›è‹¥å…¨éƒ¨ä¸º None åˆ™è¿”å› Noneã€‚
    """
    out = None
    for m in masks:
        if m is None:
            continue
        out = m if out is None else (out * m)
    return out


def expand_kv_mask(tgt_len: int, src_key_padding_mask: Optional[torch.Tensor]) -> Optional[torch.Tensor]:
    """å°†ç¼–ç å™¨çš„ padding mask æ‰©å±•æˆäº¤å‰æ³¨æ„åŠ›å¯ç”¨çš„å½¢çŠ¶ã€‚
    è¾“å…¥ï¼š src_key_padding_mask [B, 1, 1, L_src]
    è¾“å‡ºï¼š [B, 1, L_tgt, L_src]
    è¿™æ ·æ¯ä¸ªè§£ç ä½ç½®éƒ½å¯¹é½åŒä¸€ä¸ªæºåºåˆ— padding å¯è§æ€§ã€‚
    """
    if src_key_padding_mask is None:
        return None
    return src_key_padding_mask.expand(-1, 1, tgt_len, -1)


# ===================================================================
# 9) æç®€ Demoï¼šéšæœºå¤åˆ¶ä»»åŠ¡ï¼ˆnext-token é¢„æµ‹ï¼‰
# -------------------------------------------------------------------
# ç›®çš„ï¼š
# - åœ¨**ä¸ä¾èµ–æ•°æ®é›†**çš„å‰æä¸‹ï¼Œæ¼”ç¤ºå‰å‘/æŸå¤±/ä¸€æ­¥è®­ç»ƒï¼›
# - è§‚å¯Ÿå¼ é‡å½¢çŠ¶ä¸ mask æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œï¼›
# - ä¾¿äºåœ¨ IDE/Notebook å•æ­¥è°ƒè¯• attention æƒé‡ç­‰ã€‚
# æ³¨æ„ï¼šè¿™ä¸æ˜¯ä¸¥è‚ƒä»»åŠ¡ï¼Œåªä¸ºè·‘é€šæµç¨‹ä¸å½¢çŠ¶ã€‚
# ===================================================================
@dataclass
class HParams:
    src_vocab: int = 100
    tgt_vocab: int = 100
    d_model: int = 128
    num_layers: int = 2
    num_heads: int = 4
    d_ff: int = 256
    dropout: float = 0.1
    pad_id: int = 0  # çº¦å®š 0 ä¸º PAD id


def toy_batch(batch_size: int, src_len: int, tgt_len: int, vocab: int, pad_id: int = 0):
    """æ„é€ ä¸€æ‰¹éšæœºæ•´æ•°åºåˆ—ä½œä¸º src/tgtã€‚
    ä¸ºäº†ç®€å•ï¼Œè¿™é‡Œç”¨â€œteacher forcingâ€çš„æ€è·¯ï¼š
    - æ¨¡å‹è¾“å…¥ tgt_inpï¼›
    - æ ‡ç­¾ä¸º tgt_outï¼ˆ= å°† tgt_inp å‘å·¦é”™ä½ 1ï¼‰ã€‚
    è¿™æ ·å¯ç›´æ¥ç”¨äº¤å‰ç†µè®¡ç®—ä¸‹ä¸€ä¸ª token çš„é¢„æµ‹æŸå¤±ã€‚
    è¿”å›ï¼š
    - src:     [B, Ls]
    - tgt_inp: [B, Lt]
    - tgt_out: [B, Lt]
    - src_key_padding_mask: [B, Ls]  (True/1=keep)
    - tgt_key_padding_mask: [B, Lt]
    """
    B = batch_size
    # é¿å…éšæœºåˆ° pad_id=0ï¼Œè¿™é‡Œä» 2 å¼€å§‹å–å€¼ï¼ˆ1 å¯ç•™ä½œç‰¹æ®Šç¬¦å·ï¼‰
    src = torch.randint(2, vocab, (B, src_len))
    tgt_inp = torch.randint(2, vocab, (B, tgt_len))
    # å°†æ ‡ç­¾è®¾ä¸ºâ€œä¸‹ä¸€ä¸ª tokenâ€ï¼Œè¿™é‡Œåªæ˜¯ä¸ºäº†è·‘é€šæµç¨‹
    tgt_out = torch.roll(tgt_inp, shifts=-1, dims=1)

    # 1D maskï¼šTrue/1=ä¿ç•™ï¼ŒFalse/0=PAD
    src_key_padding_mask = (src != pad_id)
    tgt_key_padding_mask = (tgt_inp != pad_id)
    return src, tgt_inp, tgt_out, src_key_padding_mask, tgt_key_padding_mask


def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    hp = HParams()

    # æ„å»ºæ¨¡å‹
    model = Transformer(
        src_vocab=hp.src_vocab,
        tgt_vocab=hp.tgt_vocab,
        d_model=hp.d_model,
        num_layers=hp.num_layers,
        num_heads=hp.num_heads,
        d_ff=hp.d_ff,
        dropout=hp.dropout,
    ).to(device)

    # æ„é€ ä¸€æ‰¹æ•°æ®
    B, Ls, Lt = 8, 12, 12
    src, tgt_inp, tgt_out, src_kpm, tgt_kpm = toy_batch(B, Ls, Lt, hp.src_vocab, hp.pad_id)
    src, tgt_inp, tgt_out = src.to(device), tgt_inp.to(device), tgt_out.to(device)

    # å°† 1D çš„ True/False mask è½¬ä¸ºæ³¨æ„åŠ›å¯ç”¨çš„ 4D å½¢çŠ¶ï¼š [B,1,1,L]
    src_mask = make_padding_mask(src_kpm.to(device))      # ç¼–ç å™¨è‡ªæ³¨æ„åŠ›ä½¿ç”¨
    tgt_mask = make_padding_mask(tgt_kpm.to(device))      # ç›®æ ‡åºåˆ—å¡«å…… maskï¼ˆç¨åä¸å› æœ mask åˆå¹¶ï¼‰

    # å‰å‘è®¡ç®—ï¼šå¾—åˆ°è¯è¡¨ logits
    logits = model(src, tgt_inp, src_key_padding_mask=src_mask, tgt_key_padding_mask=tgt_mask)  # [B,Lt,V]

    # äº¤å‰ç†µæŸå¤±ï¼ˆteacher forcingï¼šé€ä½ç½®çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼‰
    loss = F.cross_entropy(logits.reshape(-1, hp.tgt_vocab), tgt_out.reshape(-1))
    print('logits å½¢çŠ¶:', logits.shape, 'loss:', float(loss.item()))

    # å¯é€‰ï¼šåšä¸€æ­¥å‚æ•°æ›´æ–°ï¼ˆè§‚å¯Ÿæ¢¯åº¦æ˜¯å¦æ­£å¸¸ï¼‰
    opt = torch.optim.AdamW(model.parameters(), lr=1e-3)
    opt.zero_grad()
    loss.backward()
    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
    opt.step()
    print('å·²å®Œæˆ 1 ä¸ªè®­ç»ƒ stepã€‚')


if __name__ == "__main__":
    main()
```





# Bert

å¥½çš„ ğŸ‘ æˆ‘ç»™ä½ åšä¸€ä¸ª**é¢è¯•é€ŸèƒŒç‰ˆ BERT çŸ¥è¯†ç‚¹æ€»ç»“**ï¼Œä¸€å£æ°”è®²å®Œå¤§æ¦‚ 1 åˆ†é’Ÿï¼Œè¦†ç›–åŸºç¡€å³å¯ã€‚

------

# ğŸš€ BERT é¢è¯•é€ŸèƒŒç‰ˆ

1. **å…¨ç§°**ï¼š**B**idirectional **E**ncoder **R**epresentations from **T**ransformersã€‚
    â†’ åŸºäº Transformer **Encoder** å †å è€Œæˆã€‚
2. **æ ¸å¿ƒæ€æƒ³**ï¼š
   - é€šè¿‡ **åŒå‘è‡ªæ³¨æ„åŠ›** åŒæ—¶å»ºæ¨¡ä¸Šä¸‹æ–‡ã€‚
   - è§£å†³ä¼ ç»Ÿè¯­è¨€æ¨¡å‹åªèƒ½å•å‘çœ‹çš„é—®é¢˜ã€‚
3. **é¢„è®­ç»ƒä»»åŠ¡**ï¼š
   - **MLMï¼ˆMasked Language Modelï¼‰**ï¼šéšæœºé®ç›– 15% çš„è¯ï¼Œè®©æ¨¡å‹é¢„æµ‹ã€‚
   - **NSPï¼ˆNext Sentence Predictionï¼‰**ï¼šåˆ¤æ–­ä¸¤å¥è¯æ˜¯å¦ç›¸é‚»ï¼ˆåç»­å¾ˆå¤šæ¨¡å‹å»æ‰ï¼‰ã€‚
4. **è¾“å…¥è¡¨ç¤º**ï¼š
   - **Token Embedding + Segment Embedding + Position Embedding**ã€‚
   - ç¬¬ä¸€ä¸ª token æ˜¯ [CLS]ï¼ˆå¥å­çº§ä»»åŠ¡ç”¨ï¼‰ï¼Œå¥å­é—´ç”¨ [SEP] åˆ†éš”ã€‚
5. **è¾“å‡ºè¡¨ç¤º**ï¼š
   - [CLS] å‘é‡ â†’ åˆ†ç±»ä»»åŠ¡ã€‚
   - å…¶ä»– token â†’ åºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼ˆNERã€é—®ç­” spanï¼‰ã€‚
6. **åº”ç”¨åœºæ™¯**ï¼š
   - æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€é—®ç­”ã€å¥å­åŒ¹é…ç­‰ã€‚
   - é€šè¿‡ **Fine-tuning**ï¼ˆåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šç»§ç»­è®­ç»ƒï¼‰ã€‚
7. **ä»£è¡¨ä¼˜åŠ¿**ï¼š
   - åŒå‘å»ºæ¨¡ï¼Œä¸Šä¸‹æ–‡ä¿¡æ¯å®Œæ•´ã€‚
   - å¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œè¿ç§»æ•ˆæœå¥½ã€‚
   - åœ¨ NLP ä»»åŠ¡ä¸Šå¤§å¹…è¶…è¶Šä¼ ç»Ÿ RNN/CNN æ¨¡å‹ã€‚

------

ğŸ‘‰ é¢è¯•å¿«é€Ÿå›ç­”æ¨¡æ¿ï¼š
 *â€œBERT æ˜¯åŸºäº Transformer Encoder çš„åŒå‘é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚å®ƒç”¨ MLM å’Œ NSP åšé¢„è®­ç»ƒï¼Œè¾“å…¥ç”± tokenã€ä½ç½®å’Œ segment embedding ç»„æˆï¼Œè¾“å‡º [CLS] å‘é‡å¯åšåˆ†ç±»ï¼Œå…¶ä»– token è¡¨ç¤ºå¯åšåºåˆ—æ ‡æ³¨ã€‚BERT çš„ä¼˜åŠ¿æ˜¯åŒå‘å»ºæ¨¡å’Œå¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œä½¿å®ƒèƒ½åœ¨å¤šç§ NLP ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¾¾åˆ°å¾ˆå¼ºçš„æ•ˆæœã€‚â€*

------

