在中国，公司 / 研究机构在开源大模型（open-source LLM）方面，近年热门并且被广泛用／提及的几个模型／系列有以下这些。我会列出几个代表性的 + 它们在行业里的优劣＋适合应用场景，这样你了解“常用”的含义。

------

# 中国开源大模型中比较常用／热门的例子

下面这些都是在技术社区／企业／AI 应用里被频繁提及、开源度比较高且活跃的模型或系列：

| 模型 / 系列                      | 发布方 / 背景        | 特点 /强项                                                   | 局限或挑战                                                   |
| -------------------------------- | -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Qwen 系列**（通义千问）        | 阿里巴巴             | 模型体量跨度大（从中小型到大型），多模态版本也在做（VR‐、图像等融合）；生态支持好，社区与工具集成强。 ([CSDN博客](https://blog.csdn.net/ECHOSON/article/details/141756580?utm_source=chatgpt.com)) | 大模型版本计算与成本要求高；在某些细分任务（例如法律/医学/高度专业领域）可能需要专门微调。 |
| **GLM 系列**                     | 智谱 AI（Zhipu AI）  | 在开源大模型“榜单”中常常排在前列，比如 GLM-4.5 在多个榜单中是第一名；混合推理、多模态（GLM-4.5V）等版本也有。 ([证券时报](https://www.stcn.com/article/detail/2975750.html?utm_source=chatgpt.com)) | 模型体量也大，对部署资源要求高；上下文长度、延迟、硬件兼容性可能是痛点；还可能在某些任务上不如专门微调的小模型表现好。 |
| **DeepSeek**（例如 DeepSeek-V3） | 深度求索（DeepSeek） | 性能与成本比不错；在数学／编码等任务中被指出与 GPT-4 / Claude 等闭源模型有可比性；开源／MIT 元许可等使其更容易商业／研究使用。 ([维基百科](https://zh.wikipedia.org/wiki/DeepSeek-V3?utm_source=chatgpt.com)) | 参数量大版本部署成本高；训练时资源消耗与推理延迟依然是瓶颈；可能在开放式对话或具备任务规划的 Agent 应用中，还需要更多优化。 |
| **Yi 系列**                      | 01.AI                | 有中大型模型，向量化／上下文长度／代码任务支持也被提到；在某些资源受限或需要效率的应用场景中，Yi 是一个比较灵活的选项。 ([维基百科](https://en.wikipedia.org/wiki/01.AI?utm_source=chatgpt.com)) | 大版本刚开源／成熟度比 Qwen 或 GLM 略低；工具生态和支持／社区资源可能稍弱；细节任务（如医、法、审计等）可能需要微调。 |
| **Kimi K2**                      | Moonshot AI          | 最近在榜单里热度很高，常与 DeepSeek / Qwen／GLM 并列；在开源排行榜中排名靠前。上下文长度／推理／多模态／Agent 能力被提及。 ([mindkeep.ai](https://www.mindkeep.ai/blogs/post/best-chinese-open-source-llms?utm_source=chatgpt.com)) | 和 DeepSeek/GLM 类似：部署资源要求高；可能某些版本尚未完全成熟；社区微调与专用任务支持还在发展中。 |

------

# 为什么这些模型“常用”／受欢迎

几个关键因素：

1. **性能 vs 成本比**：这些模型（如 DeepSeek-V3, Qwen 等）在公开 benchmark 上表现较强，同时训练或推理时的成本压力比最顶级闭源模型要低一些。
2. **开源许可**：MIT、Apache2.0 等许可使企业或研究机构更容易使用／修改／部署。
3. **生态支撑**：工具链／社区／文档／预训练 /微调代码／模型版本多样性，大家可以选合适规模的模型来用，而非一刀切。比如中小型部署、边缘部署、GPU 限制的场景。
4. **政策与产业推动**：中国政府和产业链对“自主可控”“国产模型”的重视，以及对开源的支持，使得这些模型得到了推广和应用。
5. **任务多样性需求**：从问答、对话、摘要、代码生成，到 Agent 工具调用、RAG 检索增强等，这些热门模型基本都能覆盖或能经过微调覆盖这些任务。

------

# 应用场景推荐 + 应该选哪个模型看什么

在“常用”的语境里，公司／团队选模型通常看以下几个维度：

- **硬件资源**：GPU 型号／显存／集群规模
- **延迟要求**：在线服务／离线批量处理
- **任务类型**：对话／生成／检索／代理／代码／多模态
- **上下文长度**：某些模型支持很长上下文（128k token 以上）更好
- **安全与法规**：敏感内容治理／审计／隐私保护／可控性

例如：

- 如果做对话／问答应用并且硬件充裕 → 可以考虑 DeepSeek-V3 / GLM-4.5 大版本
- 如果做代码生成＋处理长代码片段 → Qwen-Coder 或 Qwen 的编码能力强的变体
- 如果硬件资源受限，或部署在边缘／小云服务器 → Yi 系列或 GLM 等较小／中型版本

------

# 结论

所以，总结一句话：中国公司中，“最常用”的开源大模型往往是 **Qwen 系列 + GLM 系列 + DeepSeek**，其次是 **Yi 系列 / Kimi**。这些模型在开源社区、企业实践、benchmark／榜单中都频繁出现，是行业里被广泛依赖与调研的。

------

如果你愿意，我可以做一个**截止到最近**的表格：在中国公司／产品里哪些模型被用得最多（按年报／技术分享／开源下载／论文引用统计），这样更有数据支持，你要吗？