下面给你一份**可直接运行的一体化 PyTorch 教程脚本**（单文件），从“造数据 → 训练教师模型 → 评估 → 知识蒸馏训练学生模型 → 剪枝 → 量化 → LoRA 微调 → JIT 加速推理 → 对比吞吐/时延”**全流程走通**。

- 数据与模型都很小巧（2D 人造数据 + MLP），便于你在 CPU 上几分钟内跑完。
- 代码里我写了**超详细中文注释**，每个阶段都有**打印结果**与**保存/加载**示例。

> 运行方式：将下列代码保存为 `dl_full_pipeline.py`，本地安装好 PyTorch（CPU 即可），然后 `python dl_full_pipeline.py`。

------

```python
# -*- coding: utf-8 -*-
"""
一体化深度学习练习脚本（PyTorch）
---------------------------------
功能清单（全部包含、可独立开关）：
1) 造数据（自定义的二维多类数据）
2) 定义小型 MLP：Teacher（较大） / Student（较小）
3) 训练 Teacher（标准交叉熵）
4) 评估（准确率、可视化决策边界可选）
5) 知识蒸馏（KD：Teacher -> Student）
6) 剪枝（unstructured: L1）
7) 动态量化（Linear 层）
8) LoRA 微调（只训练适配器，冻结原权重）
9) JIT/trace 加速，并做简单时延对比（CPU）
10) 模型保存/加载样例（.pt）

备注：
- 仅依赖 PyTorch 标准库（不需要 numpy / scikit-learn）。
- 默认在 CPU 上运行；如有 GPU，可自动切换（但本例使用 CPU 更直观）。
- 为保证教学直观，代码冗长但结构清晰；真实工程可抽象封装。
"""

import math
import time
import random
from typing import Tuple, List

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader

# ----------------------------
# 全局配置
# ----------------------------
SEED = 42
random.seed(SEED)
torch.manual_seed(SEED)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"[Info] Using device: {DEVICE}")

# 可调的开关
DO_TRAIN_TEACHER = True         # 是否训练教师模型
DO_KD_STUDENT = True            # 是否进行知识蒸馏训练学生模型
DO_PRUNE = True                 # 是否对学生模型进行剪枝
DO_QUANT = True                 # 是否对学生模型进行动态量化
DO_LORA_FINETUNE = True         # 是否对学生模型做 LoRA 微调（冻结主干，仅训LoRA）
DO_JIT_ACCEL = True             # 是否做 JIT trace 和时延对比

# ----------------------------
# 1. 造数据（二维多类、可分但带噪）
# ----------------------------
def make_toy_2d_classification(n_per_class: int = 600,
                               n_classes: int = 3,
                               std: float = 0.8) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    生成多个高斯团（每类一个中心），增加少量噪声，便于 MLP 学习。
    输出：
        X: (N, 2) 张量
        y: (N,) 长度的整型标签
    """
    centers = []
    # 规则摆放类中心（圆环上均匀分布）
    radius = 5.0
    for k in range(n_classes):
        theta = 2 * math.pi * k / n_classes
        cx = radius * math.cos(theta)
        cy = radius * math.sin(theta)
        centers.append((cx, cy))

    xs = []
    ys = []
    for label, (cx, cy) in enumerate(centers):
        # 为每一类生成 n_per_class 个样本
        # 基于高斯分布 N(center, std^2 I)
        xk = torch.randn(n_per_class, 2) * std + torch.tensor([cx, cy])
        yk = torch.full((n_per_class,), label, dtype=torch.long)
        xs.append(xk)
        ys.append(yk)

    X = torch.cat(xs, dim=0)
    y = torch.cat(ys, dim=0)
    # 随机打乱
    idx = torch.randperm(X.size(0))
    return X[idx], y[idx]

# 划分训练/验证/测试
def split_dataset(X, y, train_ratio=0.7, val_ratio=0.15):
    N = X.size(0)
    n_train = int(N * train_ratio)
    n_val = int(N * val_ratio)
    n_test = N - n_train - n_val
    return (X[:n_train], y[:n_train],
            X[n_train:n_train+n_val], y[n_train:n_train+n_val],
            X[-n_test:], y[-n_test:])

print("[Step] Generating toy data...")
X, y = make_toy_2d_classification(n_per_class=600, n_classes=3, std=0.9)
Xtr, ytr, Xval, yval, Xte, yte = split_dataset(X, y, 0.7, 0.15)

train_loader = DataLoader(TensorDataset(Xtr, ytr), batch_size=128, shuffle=True)
val_loader   = DataLoader(TensorDataset(Xval, yval), batch_size=256, shuffle=False)
test_loader  = DataLoader(TensorDataset(Xte,  yte ), batch_size=256, shuffle=False)

# ----------------------------
# 2. 定义模型：MLP（Teacher / Student）
# ----------------------------
class MLP(nn.Module):
    """
    简单的全连接网络：
    输入维度 2（二维点），中间若干层（带 ReLU），输出为 n_classes。
    """
    def __init__(self, hidden_sizes: List[int], n_classes: int = 3):
        super().__init__()
        layers = []
        in_dim = 2
        for h in hidden_sizes:
            layers.append(nn.Linear(in_dim, h))
            layers.append(nn.ReLU(inplace=True))
            in_dim = h
        layers.append(nn.Linear(in_dim, n_classes))
        self.net = nn.Sequential(*layers)

    def forward(self, x):
        # x: (B, 2)
        return self.net(x)

# 教师模型：更宽一点
teacher = MLP(hidden_sizes=[128, 128, 64], n_classes=3).to(DEVICE)
# 学生模型：更小
student = MLP(hidden_sizes=[64, 32], n_classes=3).to(DEVICE)

# ----------------------------
# 3. 通用训练 / 评估函数
# ----------------------------
def evaluate(model, data_loader):
    """返回准确率（accuracy）。"""
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for xb, yb in data_loader:
            xb = xb.to(DEVICE).float()
            yb = yb.to(DEVICE)
            logits = model(xb)
            pred = logits.argmax(dim=1)
            correct += (pred == yb).sum().item()
            total += yb.size(0)
    return correct / max(total, 1)

def train_ce(model, data_loader, val_loader,
             epochs=50, lr=1e-3, weight_decay=1e-4, verbose=True):
    """
    标准交叉熵训练。
    """
    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    best_val = 0.0
    best_state = None
    for ep in range(1, epochs + 1):
        model.train()
        for xb, yb in data_loader:
            xb = xb.to(DEVICE).float()
            yb = yb.to(DEVICE)

            logits = model(xb)
            loss = F.cross_entropy(logits, yb)

            optim.zero_grad(set_to_none=True)
            loss.backward()
            optim.step()

        val_acc = evaluate(model, val_loader)
        if val_acc > best_val:
            best_val = val_acc
            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}

        if verbose and ep % 10 == 0:
            tr_acc = evaluate(model, data_loader)
            print(f"[Train-CE] epoch={ep:03d}  train_acc={tr_acc:.4f}  val_acc={val_acc:.4f}")

    # 恢复最佳权重
    if best_state is not None:
        model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()})

# ----------------------------
# 4. 训练 Teacher
# ----------------------------
if DO_TRAIN_TEACHER:
    print("[Step] Training TEACHER...")
    train_ce(teacher, train_loader, val_loader, epochs=60, lr=2e-3, weight_decay=1e-4)
    print(f"[Eval] Teacher | val_acc={evaluate(teacher, val_loader):.4f}  test_acc={evaluate(teacher, test_loader):.4f}")
    torch.save(teacher.state_dict(), "teacher.pt")
    print("[Save] teacher.pt")

# ----------------------------
# 5. 知识蒸馏（KD）
#    将 Teacher 的“软标签”蒸馏给 Student
# ----------------------------
def kd_train_student(student_model, teacher_model, data_loader, val_loader,
                     epochs=60, lr=2e-3, alpha=0.5, T=4.0):
    """
    KD 的常见损失：
    L = alpha * CE(student_logits, y_true) + (1 - alpha) * KL(softmax(s/T), softmax(t/T)) * (T^2)
    - T: 温度（拉平分布）
    - alpha: 真实标签与软目标的权重平衡
    """
    teacher_model.eval()
    for p in teacher_model.parameters():
        p.requires_grad_(False)

    opt = torch.optim.Adam(student_model.parameters(), lr=lr)

    best_val = 0.0
    best_state = None

    for ep in range(1, epochs + 1):
        student_model.train()
        for xb, yb in data_loader:
            xb = xb.to(DEVICE).float()
            yb = yb.to(DEVICE)

            with torch.no_grad():
                t_logits = teacher_model(xb)

            s_logits = student_model(xb)
            # 交叉熵（硬标签）
            loss_ce = F.cross_entropy(s_logits, yb)

            # KL 散度（软标签，注意 log_softmax 与 softmax 的搭配）
            s_log_prob = F.log_softmax(s_logits / T, dim=1)
            t_prob = F.softmax(t_logits / T, dim=1)
            loss_kd = F.kl_div(s_log_prob, t_prob, reduction="batchmean") * (T * T)

            loss = alpha * loss_ce + (1 - alpha) * loss_kd

            opt.zero_grad(set_to_none=True)
            loss.backward()
            opt.step()

        val_acc = evaluate(student_model, val_loader)
        if val_acc > best_val:
            best_val = val_acc
            best_state = {k: v.cpu().clone() for k, v in student_model.state_dict().items()}

        if ep % 10 == 0:
            tr_acc = evaluate(student_model, data_loader)
            print(f"[KD] epoch={ep:03d}  train_acc={tr_acc:.4f}  val_acc={val_acc:.4f}")

    if best_state is not None:
        student_model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()})

if DO_KD_STUDENT:
    print("[Step] KD training STUDENT (from TEACHER)...")
    # 先用少量 epochs 快速训出一个不错的 Student
    kd_train_student(student, teacher, train_loader, val_loader, epochs=60, lr=2e-3, alpha=0.6, T=4.0)
    print(f"[Eval] Student-KD | val_acc={evaluate(student, val_loader):.4f}  test_acc={evaluate(student, test_loader):.4f}")
    torch.save(student.state_dict(), "student_kd.pt")
    print("[Save] student_kd.pt")
else:
    # 如果不做 KD，可退化为标准 CE 训练学生：
    print("[Step] Training STUDENT (CE only)...")
    train_ce(student, train_loader, val_loader, epochs=60, lr=2e-3)
    print(f"[Eval] Student | val_acc={evaluate(student, val_loader):.4f}  test_acc={evaluate(student, test_loader):.4f}")

# ----------------------------
# 6. 剪枝（Pruning）
#    采用 unstructured L1 不结构化剪枝，示范对 Linear 层的权重做比例剪枝
# ----------------------------
if DO_PRUNE:
    print("[Step] Pruning STUDENT...")
    import torch.nn.utils.prune as prune

    def apply_prune_l1(module: nn.Module, amount=0.3):
        """
        对传入模块中的 Linear 层进行 L1 不结构化剪枝：
        - amount: 0~1，表示按比例剪枝的参数量
        剪枝后会以参数重参数化（weight_orig + mask）方式存在；最后可选择 prune.remove 固化。
        """
        for name, sub in module.named_modules():
            if isinstance(sub, nn.Linear):
                prune.l1_unstructured(sub, name="weight", amount=amount)
                # （可选）也可对 bias 剪枝，但通常仅对 weight
        return module

    student = apply_prune_l1(student, amount=0.4)

    # 剪枝后微调（短暂几轮），以恢复精度
    train_ce(student, train_loader, val_loader, epochs=15, lr=1e-3, weight_decay=0.0, verbose=False)
    acc_after = evaluate(student, test_loader)
    print(f"[Eval] After pruning+finetune | test_acc={acc_after:.4f}")

    # 将剪枝从重参数化变为真实稀疏（去掉 mask，固化当前权重）
    def remove_prune_reparam(module: nn.Module):
        for sub in module.modules():
            if isinstance(sub, nn.Linear):
                try:
                    prune.remove(sub, "weight")
                except Exception:
                    pass
        return module

    student = remove_prune_reparam(student)
    torch.save(student.state_dict(), "student_pruned.pt")
    print("[Save] student_pruned.pt")

# ----------------------------
# 7. 动态量化（Dynamic Quantization）
#    对 Linear 层做 int8 动态量化（推理时对权重量化）
# ----------------------------
quantized_student = None
if DO_QUANT:
    print("[Step] Dynamic Quantization...")
    try:
        # 新 API 路径（PyTorch 1.13+）：torch.ao.quantization
        from torch.ao.quantization import quantize_dynamic
        quant_api = "torch.ao.quantization.quantize_dynamic"
    except Exception:
        # 老 API 兼容
        from torch.quantization import quantize_dynamic
        quant_api = "torch.quantization.quantize_dynamic"

    quantized_student = quantize_dynamic(
        student.cpu(),  # 动态量化一般在 CPU 上
        {nn.Linear},    # 指定要量化的层类型集合
        dtype=torch.qint8
    )
    q_acc = evaluate(quantized_student, test_loader)
    print(f"[Eval] Quantized(Student) | test_acc={q_acc:.4f}  (API={quant_api})")
    torch.save(quantized_student.state_dict(), "student_quant_dynamic.pt")
    print("[Save] student_quant_dynamic.pt")

# ----------------------------
# 8. LoRA 微调
#    仅对 Linear 增加低秩适配器（A: in->r, B: r->out），冻结原权重，仅训练 LoRA
# ----------------------------
class LoRALinear(nn.Module):
    """
    LoRA 适配的 Linear：y = x W^T + x (B A)^T
    - 冻结 W，仅训练 A/B（低秩 r）
    - 推理时可将 (B@A) 与 W 合并或保持显式求和
    """
    def __init__(self, base_linear: nn.Linear, r: int = 8, alpha: float = 1.0):
        super().__init__()
        assert isinstance(base_linear, nn.Linear)
        self.in_features = base_linear.in_features
        self.out_features = base_linear.out_features
        self.r = r
        self.alpha = alpha

        # 冻结原始权重
        self.weight = nn.Parameter(base_linear.weight.data.clone(), requires_grad=False)
        self.bias = None
        if base_linear.bias is not None:
            self.bias = nn.Parameter(base_linear.bias.data.clone(), requires_grad=False)

        # LoRA 低秩分解参数：A: in->r, B: r->out
        # 常见初始化：A 零、B 零 或小值，这里用小随机并缩放
        self.A = nn.Parameter(torch.zeros(self.r, self.in_features))
        self.B = nn.Parameter(torch.zeros(self.out_features, self.r))

        # 参考实现里 often A init ~ N(0, 0.02), B init zero；这里给一个温和初始化
        nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))
        nn.init.zeros_(self.B)

        # 缩放系数（有的实现使用 alpha/r）
        self.scaling = self.alpha / self.r

    def forward(self, x):
        # x: (B, in_features)
        base = F.linear(x, self.weight, self.bias)  # 冻结部分
        lora = F.linear(x, (self.B @ self.A) * self.scaling, None)
        return base + lora

def inject_lora(model: nn.Module, r=8, alpha=1.0, target_types=(nn.Linear,)):
    """
    递归遍历，将指定类型层替换为 LoRA 版本（保持形状一致）。
    """
    for name, module in model.named_children():
        if isinstance(module, target_types):
            setattr(model, name, LoRALinear(module, r=r, alpha=alpha))
        else:
            inject_lora(module, r=r, alpha=alpha, target_types=target_types)
    return model

if DO_LORA_FINETUNE:
    print("[Step] LoRA fine-tune on STUDENT...")
    # 复制一个学生模型（使用剪枝后的参数更贴近部署情景）
    lora_student = MLP(hidden_sizes=[64, 32], n_classes=3)
    # 从现有 student 拷贝权重
    lora_student.load_state_dict({k: v.cpu() for k, v in student.state_dict().items()})
    lora_student = inject_lora(lora_student, r=6, alpha=6.0, target_types=(nn.Linear,))
    lora_student.to(DEVICE)

    # 只训练 LoRA 参数
    for p in lora_student.parameters():
        p.requires_grad_(False)
    for m in lora_student.modules():
        if isinstance(m, LoRALinear):
            m.A.requires_grad_(True)
            m.B.requires_grad_(True)

    # 用少量 epoch 微调
    opt = torch.optim.Adam(filter(lambda p: p.requires_grad, lora_student.parameters()), lr=2e-3)
    for ep in range(1, 21):
        lora_student.train()
        for xb, yb in train_loader:
            xb = xb.to(DEVICE).float()
            yb = yb.to(DEVICE)
            logits = lora_student(xb)
            loss = F.cross_entropy(logits, yb)
            opt.zero_grad(set_to_none=True)
            loss.backward()
            opt.step()

        if ep % 5 == 0:
            acc = evaluate(lora_student, val_loader)
            print(f"[LoRA] epoch={ep:02d}  val_acc={acc:.4f}")

    acc_test = evaluate(lora_student, test_loader)
    print(f"[Eval] LoRA-Student | test_acc={acc_test:.4f}")
    torch.save(lora_student.state_dict(), "student_lora.pt")
    print("[Save] student_lora.pt")

# ----------------------------
# 9. JIT/Trace 加速与时延对比（CPU）
#    注意：量化后的模型 & 含 LoRA 的模型也可分别对比
# ----------------------------
def benchmark_latency(model, n_warmup=50, n_iters=200, batch_size=512, note=""):
    """
    简单的 CPU 推理时延基准（单线程可选：请在外部设置 OMP_NUM_THREADS=1 等）。
    """
    model.eval()
    x = torch.randn(batch_size, 2)
    with torch.no_grad():
        # 预热
        for _ in range(n_warmup):
            _ = model(x)

        # 计时
        t0 = time.perf_counter()
        for _ in range(n_iters):
            _ = model(x)
        t1 = time.perf_counter()

    avg_ms = (t1 - t0) * 1000.0 / n_iters
    print(f"[Bench] {note:>14}  batch={batch_size}  avg_latency={avg_ms:.3f} ms")
    return avg_ms

if DO_JIT_ACCEL:
    print("[Step] JIT trace & latency benchmark (CPU)...")
    # 准备三个版本对比：原始学生、量化学生（可选）、JIT 学生
    base_cpu = student.cpu().eval()
    inp = torch.randn(1, 2)

    # baseline
    benchmark_latency(base_cpu, note="Student (FP32)")

    # JIT trace
    with torch.no_grad():
        traced = torch.jit.trace(base_cpu, inp)
    benchmark_latency(traced, note="Student (JIT)")

    # 若存在动态量化模型，亦对比
    if quantized_student is not None:
        benchmark_latency(quantized_student.eval(), note="Student (DynamicInt8)")

    # LoRA 版对比（可选）
    if DO_LORA_FINETUNE:
        lora_cpu = lora_student.cpu().eval()
        benchmark_latency(lora_cpu, note="LoRA-Student")

        with torch.no_grad():
            lora_traced = torch.jit.trace(lora_cpu, inp)
        benchmark_latency(lora_traced, note="LoRA-Student (JIT)")

print("\n[Done] 全流程演示结束。你可以查看生成的 *.pt 文件，并尝试加载推理。")

# ----------------------------
# 10. 加载示例（供参考，不自动执行）
# ----------------------------
"""
# 例：如何加载并使用保存的模型
model = MLP(hidden_sizes=[64, 32], n_classes=3)
state = torch.load("student_pruned.pt", map_location="cpu")
model.load_state_dict(state)
model.eval()
with torch.no_grad():
    x = torch.randn(5, 2)
    logits = model(x)
    pred = logits.argmax(dim=1)
    print(pred)
"""
```

------

## 你能学到什么（要点回顾）

- **造数据**：不用外部库，用高斯团做 2D 多类分类，便于快速实验。
- **模型**：Teacher 大、Student 小；MLP 便于看清剪枝/量化/LoRA 的效果。
- **训练**：交叉熵标准流程 + early best 恢复；KD 结合软目标（温度 T）与硬标签（alpha 权衡）。
- **剪枝**：`torch.nn.utils.prune` 先重参数化（mask），微调恢复，再 `prune.remove` 固化稀疏。
- **量化**：示范**动态量化**（Linear → int8）；极简、部署常用。
- **LoRA**：实现可替换的 `LoRALinear`，冻结主干、只训 A/B，少量 epoch 即可微调。
- **加速**：JIT trace 做轻量图优化；同时对比 FP32 / JIT / 动态量化 的**平均时延**。
- **保存/加载**：`.pt` 权重示例，便于后续重现或部署。

> 想继续扩展：
>
> 1. 把量化换成**静态量化/QAT**（需要校准/观测器）；
> 2. 把剪枝改成**结构化剪枝**（如按通道剪枝）并联动蒸馏；
> 3. 把 LoRA 合并成权重导出（B@A 融入 W）；
> 4. 增加**ONNX 导出**并在 onnxruntime 测速。

